--- File: ./README.md ---
# üåü Awesome Masa

A curated collection of datasets, tools, and agents for AI developers using the Masa protocol.

[Masa Protocol](https://github.com/masa-finance/masa-oracle)

## üöÄ Quick Start

1. Ensure you have Conda installed.
2. Create the environment:

   ```bash
   conda env create -f environment.yml
   conda activate awesome-masa
   ```

3. Set up environment variables:
   - Copy `env.example` to `.env`
   - Fill in the required values

## üìö Contents

### [Datasets](#datasets)

### [Scrapers](#scrapers)

### [Agents](#agents)

### [Contribution](#contribution)

### [License](#license)

## üìä Datasets

Our repository includes various datasets scraped and processed using the Masa Protocol:

### üê¶ Twitter Data

Scraped tweets related to various topics, including memecoin discussions.

*For more details, check out the [datasets README](datasets/README.md).*

### üéôÔ∏è Podcast Data

- **Diarized Transcripts**: Podcast episodes with speaker identification and timestamps.
- **Examples**: Bankless, Huberman Lab, Laura Shin, Real Vision, The Mint Condition

### üí¨ Discord Data

- **Channel Data**: Messages from Discord channels, including user information and timestamps.
- **Examples**: Guild: Masa, Channel ID: 1217114388373311640

This dataset contains community conversations related to Masa.

### üì∫ YouTube Data

A collection of YouTube video transcripts, diarized with speaker labels.

## üï∑Ô∏è Scrapers

We provide several scraper libraries to collect data from different sources using the Masa Protocol:

- **Tweet Fetcher**: Retrieve tweets from specified Twitter accounts.
- **Discord Scraper**: Fetch and save messages from Discord channels.

*For usage instructions, refer to the respective README files in the `scrapers` directory.*

## ü§ñ Agents

We provide example code for simple RAG (Retrieval-Augmented Generation) agents using our datasets. These agents demonstrate how to leverage the Masa protocol's structured data in AI applications.

### Example RAG Agent

Our example RAG agent showcases:

- Loading and preprocessing Masa datasets
- Implementing vector search for relevant context retrieval
- Integrating retrieved context with a language model for enhanced responses

*For the full implementation, see the [RAG example agent](agents/rag_example.py) file.*

## ü§ù Contribution

We welcome contributions! If you have a dataset, tool, or agent that fits well with our collection, feel free to submit a pull request or open an issue.

For more information on using these datasets or contributing, please refer to the documentation or contact us directly.

## üìÑ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

### *Made with ‚ù§Ô∏è by the Masa Foundation*


--- File: ./accountMappings.py ---
ACCOUNT_MAPPINGS = {
    'NEARMobile_app': [
        'nearmobile.app', 'nearmobile', 'mobile app', 'wallet', 'nearwallet',
        'noncustodial', 'selfcustodial', 'peersyst', 'mobile', 'crypto wallet',
        'blockchain', 'NEAR', 'decentralized', 'self-custody', 'app'
    ],
    'NEARMintern': [
        'intern', 'NEARMobile', 'dapps', 'developer', 'blockchain',
        'learning', 'mobile development', 'NEAR', 'apprenticeship'
    ],
    'nearblocks': [
        'explorer', 'blocks', 'onchain', 'data', 'nearblock', 'txhash',
        'transactions', 'blockchain explorer', 'analytics', 'NEAR',
        'blockchain data', 'monitoring', 'block explorer'
    ],
    'NEARProtocol': [
        'nearprotocol', 'near', 'nearfoundation', 'illia', 'news',
        'blockchain', 'protocol', 'foundation', 'updates',
        'crypto', 'technology', 'development', 'community'
    ],
    'finance_ref': [
        'ref', 'reffinance', 'dapp', 'swap', 'pools', 'liquiditypools',
        'trade', 'amm', 'usdc', 'usdt', 'frax', 'top', 'tvl', 'finance',
        'DEX', 'liquidity', 'DeFi', 'trading', 'NEAR', 'REF Finance',
        'automated market maker', 'cryptocurrency'
    ],
    'ref_intern': [
        'ref', 'intern', 'dapp', 'swap', 'pools', 'liquiditypools',
        'trade', 'amm', 'usdc', 'usdt', 'frax', 'top', 'tvl', 'internship',
        'developer', 'learning', 'DeFi', 'NEAR', 'REF Finance',
        'cryptocurrency', 'AMM'
    ],
    'meta_pool': [
        'pool', 'pools', 'stake', 'stNEAR', 'mpDAO', 'dao', 'reStake',
        'liquid', 'tvl', 'dapp', 'Meta Pool', 'staking', 'liquid staking',
        'NEAR', 'DeFi', 'liquidity', 'staking pool', 'cryptocurrency'
    ],
    'burrow_finance': [
        'lending', 'lend', 'borrow', 'burrow', 'usdc', 'usdt', 'frax',
        'stake', 'pools', 'tvl', 'dapp', 'Burrow Finance', 'DeFi', 'NEAR',
        'crypto lending', 'liquidity', 'borrowing', 'loans', 'stablecoins',
        'finance'
    ],
    'beepopula': [
        'community', 'dapp', 'privacy', 'onchain', 'social', 'BeePopula',
        'social media', 'blockchain', 'NEAR', 'decentralized app',
        'community platform', 'on-chain social'
    ],
    'DeltaBotTeam': [
        'dca', 'trade', 'gachapon', 'airdrop', 'swing', 'bots', 'ai',
        'stablecoin', 'usdc', 'usdt', 'aibot', 'tradebot', 'tokens',
        'auto', 'dapp', 'Delta Bot Team', 'automated trading', 'NEAR',
        'cryptocurrency', 'trading signals'
    ],
    'shitzuonnear': [
        'dogshit', 'shitzu', 'meme', 'stake', 'validator', 'dev', 'build',
        'NEAR', 'memecoin', 'blockchain', 'cryptocurrency', 'developer',
        'staking', 'community'
    ],
    'memedotcooking': [
        'meme', 'memecoin', 'launchpad', 'buy', 'sell', 'rug',
        'meme.cooking', 'cook', 'memecooking', 'shitzu', 'dogshit', 'NEAR',
        'cryptocurrency', 'token', 'trading', 'blockchain', 'cooking'
    ],
    'sharddog': [
        'nft', 'nfts', 'mint', 'sharddog', 'community', 'build',
        'blockchain', 'NEAR', 'collectibles', 'digital art', 'crypto',
        'non-fungible tokens'
    ],
    'nadabots': [
        'certificate', 'did', 'proof', 'humanproof', 'id', 'bots', 'nada',
        'identity', 'verification', 'blockchain', 'decentralized identity',
        'NEAR', 'authentication'
    ],
    'potlock_': [
        'funding', 'ai', 'design', 'potlock', 'pot', 'startup',
        'artificial intelligence', 'investment', 'entrepreneurship',
        'innovation', 'technology', 'development', 'AGI'
    ],
    'JumpDeFi': [
        'jump', 'defi', 'stake', 'nft', 'DeFi', 'staking', 'NFT',
        'crypto', 'blockchain', 'NEAR', 'finance', 'cryptocurrency',
        'investment'
    ],
    'TokenBridgeApp': [
        'bridge', 'swap', 'transfer', 'crosschain', 'solana', 'binance',
        'arbitrum', 'token', 'blockchain', 'NEAR', 'cryptocurrency',
        'exchange', 'interoperability', 'multi-chain', 'token bridge'
    ],
    'tknhomes': [
        'token', 'marketplace', 'launchpad', 'meme', 'memecoin', 'NEAR',
        'cryptocurrency', 'blockchain', 'trading', 'tokens', 'home',
        'real estate', 'investment'
    ],
    'NEARDevHub': [
        'dev', 'build', 'ai', 'chain', 'onnear', 'devrel', 'tutorial',
        'NEAR', 'developer', 'development', 'blockchain', 'learning',
        'resources', 'community', 'education', 'development hub'
    ],
    'NEARdevs': [
        'dev', 'build', 'ai', 'chain', 'onnear', 'NEAR', 'developers',
        'development', 'blockchain', 'artificial intelligence',
        'community', 'technology', 'coding'
    ],
    'ilblackdragon': [
        'founder', 'illia', 'dev', 'build', 'nearceo', 'boss',
        'blackdragon', 'nearprotocol', 'nearfoundation', 'NEAR',
        'blockchain', 'CEO', 'developer', 'entrepreneur', 'technology',
        'leadership', 'innovation'
    ],
    'GNearAi': [
        'meme', 'ai', 'NEAR', 'artificial intelligence', 'memes', 'crypto',
        'blockchain', 'technology', 'machine learning', 'innovation'
    ],
    'vxyz_near': [
        'community', 'NEAR', 'blockchain', 'network', 'crypto',
        'engagement', 'collaboration'
    ],
    'NEARQuant': [
        'community', 'news', 'alpha', 'NEAR', 'blockchain',
        'quantitative analysis', 'trading', 'crypto', 'insights',
        'market analysis', 'data'
    ],
    'taostats': [
        'ai', 'bittensor', 'masaAI', 'web3', 'blockchain', 'statistics',
        'data', 'analysis', 'artificial intelligence', 'cryptocurrency',
        'machine learning', 'neural networks'
    ],
    'nearcatalog': [
        'community', 'dapps', 'dappradar', 'projects', 'news', 'trends',
        'NEAR', 'catalog', 'applications', 'blockchain', 'directory',
        'crypto', 'project listing', 'ecosystem'
    ],
    'marior_dev': [
        'community', 'dev', 'shitzu', 'orderly', 'futures', 'derivatives',
        'developer', 'NEAR', 'blockchain', 'trading', 'crypto', 'memecoin',
        'financial instruments', 'programming'
    ],
    'SKYTONET_': [
        'community', 'mod', 'ambassador', 'ref', 'shitzu', 'meme',
        'memedotcooking', 'NEAR', 'moderator', 'ambassador', 'blockchain',
        'crypto', 'memecoin', 'cooking', 'engagement'
    ],
    'invokerlabs': [
        'dev', 'build', 'nearblocks', 'NEAR', 'developer', 'blockchain',
        'technology', 'innovation', 'laboratory', 'software development',
        'solutions'
    ],
    'Nearsend_io': [
        'dev', 'nep', 'send', 'invokerlabs', 'bulk', 'transactions',
        'NEAR', 'developer', 'blockchain', 'sending', 'crypto',
        'transactions', 'NEP standards', 'messaging'
    ],
    'questflow': [
        'project', 'dapp', 'ai', 'agents', 'NEAR', 'blockchain',
        'artificial intelligence', 'decentralized app', 'automation',
        'workflow', 'task management', 'productivity'
    ],
    'DayTrader888': [
        'growth', 'veax', 'dex', 'degen', 'day trading', 'NEAR',
        'blockchain', 'crypto', 'decentralized exchange', 'finance',
        'cryptocurrency', 'trading strategies'
    ],
    'NearKatToken': [
        'meme', 'memecoin', 'token', 'kat', 'cat', 'NEAR',
        'cryptocurrency', 'blockchain', 'token', 'memecoin',
        'cat-themed', 'crypto asset', 'community token'
    ],
    'ai_pgf': [
        'potlock', 'ai', 'funding', 'agi', 'artificial intelligence',
        'investment', 'NEAR', 'blockchain', 'AGI (Artificial General Intelligence)',
        'technology', 'startup funding'
    ],
    'hotdao_': [
        'hot', 'herewallet', 'dao', 'telegram', 'NEAR', 'community',
        'decentralized autonomous organization', 'blockchain', 'wallet',
        'communication', 'messaging'
    ],
    'p_volnov': [
        'hotdao', 'herewallet', 'founder', 'dev', 'NEAR', 'developer',
        'blockchain', 'entrepreneur', 'technology', 'leadership',
        'wallet development'
    ],
    'ThunderHoodlab': [
        'meme', 'dex', 'marketplace', 'launchpad', 'trade', 'deploy',
        'NEAR', 'blockchain', 'cryptocurrency', 'decentralized exchange',
        'trading', 'development', 'cryptocurrency exchange'
    ],
    'getmasafi': [
        'ai', 'agents', 'scrape', 'data', 'twitterscrape', 'discord',
        'telegram', 'web', 'webscrape', 'mine', 'bittensor', 'tao',
        'blockchain', 'data mining', 'artificial intelligence',
        'social media', 'automation'
    ],
    'growthmate_xyz': [
        'data', 'onchain', 'dapps', 'trends', 'community', 'NEAR',
        'blockchain', 'analytics', 'growth', 'crypto', 'market trends',
        'user engagement'
    ],
    'NearGamesDAO': [
        'community', 'game', 'gamers', 'dao', 'play', 'NEAR',
        'blockchain', 'gaming', 'decentralized autonomous organization',
        'crypto', 'entertainment', 'interactive'
    ],
    'SailGPESP': [
        'sailgp', 'nearspain', 'nearesp', 'nearpartners', 'nearsports',
        'NEAR', 'blockchain', 'sailing', 'sports', 'Spain',
        'partnerships', 'events'
    ],
    'elm_money': [
        'founder', 'ai', 'community', 'neardc', 'digital', 'marketing',
        'dao', 'aurora', 'apps', 'games', 'NEAR', 'blockchain',
        'entrepreneur', 'technology', 'digital marketing', 'development'
    ],
    'KagemniKarimu': [
        'dev', 'devrel', 'lava', 'magma', 'lavanet', 'rpc', 'data',
        'apps', 'host', 'storage', 'NEAR', 'blockchain', 'developer',
        'infrastructure', 'remote procedure call', 'software'
    ],
    'xgilxgil': [
        'dev', 'lava', 'lavanet', 'rpc', 'magma', 'NEAR', 'blockchain',
        'developer', 'infrastructure', 'technology', 'networking'
    ],
    'magmadevs': [
        'dev', 'lava', 'lavanet', 'magma', 'NEAR', 'blockchain',
        'developer', 'infrastructure', 'software development',
        'technology', 'network solutions'
    ],
    'consensus128': [
        'marketing', 'community', 'lava', 'rpc', 'NEAR', 'blockchain',
        'infrastructure', 'communication', 'promotion', 'networking',
        'technology'
    ],
    'theinterestedr1': [
        'founder', 'cto', 'lava', 'dev', 'build', 'NEAR', 'blockchain',
        'developer', 'technology', 'leadership', 'innovation',
        'infrastructure'
    ],
    'NimrodxLava': [
        'dev', 'lava', 'r&d', 'magma', 'NEAR', 'blockchain',
        'research and development', 'developer', 'technology',
        'innovation', 'infrastructure'
    ],
    'beanonnear': [
        'meme', 'memecoin', 'token', 'mrbean', 'stake', 'nft', 'ref',
        'jump', 'NEAR', 'blockchain', 'cryptocurrency', 'staking',
        'non-fungible tokens', 'DEX', 'finance', 'comedy'
    ],
    'fraxfinance': [
        'stable', 'coin', 'token', 'lend', 'borrow', 'defi', 'fiat',
        'stake', 'sfrax', 'NEAR', 'blockchain', 'cryptocurrency',
        'stablecoin', 'finance', 'lending', 'borrowing', 'DeFi'
    ],
    'OpenForest_': [
        'rwa', 'onchain', 'carbon', 'consensuslayer', 'layer', 'defi',
        'stake', 'lending', 'bonds', 'token', 'OpenForest', 'real-world assets',
        'carbon credits', 'DeFi', 'staking', 'tokenization', 'environmental',
        'sustainability', 'blockchain', 'NEAR', 'green finance', 'ESG',
        'climate change', 'sustainable finance'
    ],
    'edgevideoai': [
        'stream', 'space', 'video', 'fast', 'revenue', 'edge', 'ai',
        'EdgeVideo AI', 'streaming', 'edge computing', 'artificial intelligence',
        'blockchain', 'NEAR', 'monetization', 'video streaming', 'technology',
        'content delivery', 'media'
    ],
    'pironidi': [
        'didier', 'defi', 'dev', 'growth', 'founder', 'pikespeak',
        'ref', 'reffinance', 'Didier', 'DeFi', 'developer', 'growth',
        'founder', 'Pikes Peak', 'REF Finance', 'NEAR', 'blockchain',
        'entrepreneurship', 'finance', 'cryptocurrency', 'innovation',
        'DEX', 'decentralized exchange'
    ],
    'NEARChainStatus': [
        'onchain', 'data', 'validator', 'infra', 'community', 'news',
        'devrel', 'updates', 'status', 'NEAR Chain Status', 'on-chain data',
        'infrastructure', 'blockchain', 'NEAR', 'network status',
        'node monitoring', 'development updates', 'network health',
        'system status'
    ],
    'marrowng': [
        'metapool', 'marketing', 'founder', 'community', 'latam', 'espa√±ol',
        'Marrow NG', 'blockchain', 'NEAR', 'Latin America', 'Spanish',
        'staking', 'liquid staking', 'entrepreneurship', 'growth',
        'communication'
    ],
    'noahmajor1776': [
        'nono', 'nearmaxi', 'content', 'creator', 'community', 'news',
        'dev', 'Noah Major', 'NEAR Maxi', 'blockchain', 'NEAR',
        'developer', 'crypto enthusiast', 'social media', 'content creation'
    ],
    'NEAR_Arabic': [
        'nation', 'arab', 'language', 'community', 'NEAR Arabic',
        'blockchain', 'NEAR', 'Arabic language', 'Middle East',
        'community events', 'updates', 'localization', 'education'
    ],
    'EsNearEs': [
        'espa√±ol', 'latam', 'noticias', 'news', 'community', 'EsNearEs',
        'Spanish', 'blockchain', 'NEAR', 'Latin America', 'community',
        'events', 'updates', 'crypto news'
    ],
    'NearPositive': [
        'community', 'news', 'NEAR Positive', 'blockchain', 'NEAR',
        'updates', 'crypto news', 'engagement', 'information', 'positive news'
    ],
    'Near_Colombia': [
        'latam', 'nation', 'espa√±ol', 'colombia', 'news', 'community',
        'NEAR Colombia', 'blockchain', 'NEAR', 'Latin America', 'Spanish',
        'community events', 'updates', 'Colombia'
    ],
    'MITTE_gg': [
        'nft', 'dapp', 'nftmarketplace', 'trade', 'trading', 'MITTE',
        'blockchain', 'NEAR', 'NFTs', 'marketplace', 'decentralized app',
        'buy', 'sell', 'collectibles', 'crypto art'
    ],
    'EvgenSkydan': [
        'ukraine', 'ucrania', 'nearua', 'nearuaguild', 'neardc', 'explorer',
        'news', 'dev', 'onchain', 'community', 'Evgen Skydan', 'blockchain',
        'NEAR', 'developer', 'Ukraine', 'community member', 'on-chain data',
        'NEAR UA Guild'
    ],
    'jjyuannear': [
        'jerry', 'yuannear', 'nearusa', 'usa', 'banyan', 'founder', 'news',
        'dev', 'devrel', 'community', 'Jerry Yuan', 'blockchain', 'NEAR',
        'developer', 'entrepreneur', 'USA', 'community events', 'developer relations'
    ],
    'Banyan_NEAR': [
        'build', 'dev', 'project', 'banyan', 'nearprotocol', 'develop',
        'Banyan NEAR', 'blockchain', 'NEAR', 'development', 'projects',
        'technology', 'innovation', 'software'
    ],
    'SourceDegen': [
        'degen', 'community', 'Source Degen', 'blockchain', 'NEAR',
        'crypto enthusiast', 'community engagement', 'trading', 'DeFi',
        'cryptocurrency'
    ],
    'rendal73': [
        'degen', 'community', 'Rendal', 'blockchain', 'NEAR', 'crypto enthusiast',
        'community member', 'trading', 'cryptocurrency', 'engagement'
    ],
    'n0trdame': [
        'degen', 'community', 'Notrdame', 'blockchain', 'NEAR',
        'crypto enthusiast', 'community member', 'trading', 'cryptocurrency'
    ],
    'here_wallet': [
        'wallet', 'competition', 'hot', 'telegram', 'Here Wallet',
        'blockchain', 'NEAR', 'cryptocurrency', 'security', 'user-friendly',
        'crypto wallet', 'technology', 'communication'
    ],
    'cosmos': [
        'cosmos', 'cosmossdk', 'ibc', 'consensuslayer', 'layer', 'atom',
        'Cosmos', 'blockchain', 'Cosmos SDK', 'IBC', 'Inter-Blockchain Communication',
        'consensus layer', 'ATOM', 'network', 'cryptocurrency', 'ecosystem'
    ],
    'axelar': [
        'bridge', 'axelar', 'token', 'Axelar', 'blockchain', 'cross-chain',
        'interoperability', 'token bridge', 'cryptocurrency', 'network',
        'security', 'decentralized'
    ],
    'EvmosOrg': [
        'evm', 'network', 'evmos', 'Evmos', 'blockchain', 'EVM compatible',
        'network', 'Cosmos', 'Ethereum Virtual Machine', 'interoperability',
        'cryptocurrency', 'development'
    ],
    'osmosiszone': [
        'osmosis', 'cosmos', 'atom', 'Osmosis', 'blockchain',
        'Cosmos', 'ATOM', 'decentralized exchange', 'DEX', 'liquidity',
        'staking', 'cryptocurrency', 'trading'
    ],
    'near_malaysia': [
        'nation', 'community', 'malaysia', 'malasia', 'asia', 'NEAR Malaysia',
        'blockchain', 'NEAR', 'community events', 'updates', 'localization',
        'development', 'Southeast Asia'
    ],
    'ekosubagyo': [
        'maxone', 'metapool', 'community', 'ambassador', 'Eko Subagyo',
        'blockchain', 'NEAR', 'Meta Pool', 'community engagement',
        'ambassador', 'staking', 'liquid staking', 'crypto enthusiast'
    ],
    'alannetwork_': [
        'metapool', 'latam', 'openweb', 'dev', 'Alan Network',
        'blockchain', 'NEAR', 'Meta Pool', 'Latin America', 'developer',
        'open web', 'technology', 'innovation'
    ],
    'swisshustler': [
        'nearprotocol', 'swiss', 'nearfoundation', 'Swiss Hustler',
        'blockchain', 'NEAR', 'Switzerland', 'entrepreneur', 'technology',
        'development', 'community', 'innovation'
    ],
    'Mikikin8': [
        'defi', 'founder', 'dev', 'defishards', 'shards',
        'Mikikin', 'blockchain', 'NEAR', 'DeFi', 'developer', 'founder',
        'sharding', 'finance', 'innovation'
    ],
    'DeFiShardsxyz': [
        'defi', 'sharding', 'shards', 'defishards', 'nft', 'docs',
        'liquid', 'stake', 'DeFi Shards', 'blockchain', 'NEAR', 'DeFi',
        'sharding', 'NFTs', 'documentation', 'liquid staking', 'finance'
    ],
    'mraltantutar': [
        'nearprotocol', 'nearfoundation', 'georgia', 'founder', 'dev',
        'chain', 'chainabstracted', 'signatures', 'Mr. Altantutar', 'blockchain',
        'NEAR', 'developer', 'founder', 'chain abstraction', 'cryptography',
        'signatures', 'Georgia (country)'
    ],
    'aescobarindo': [
        'escobar', 'reffinance', 'ref', 'dapdap', 'dex', 'dev', 'marketing',
        'community', 'founder', 'playember', 'A. Escobar', 'blockchain',
        'NEAR', 'developer', 'marketing', 'community engagement',
        'decentralized exchange', 'gaming'
    ],
    'chronear': [
        'dev', 'build', 'chain', 'chainabstraction', 'abstraction',
        'signatures', 'chainsig', 'Chron NEAR', 'blockchain', 'NEAR',
        'developer', 'chain abstraction', 'cryptography', 'innovation',
        'technology'
    ],
    'NearIndia': [
        'india', 'asia', 'nation', 'community', 'dev', 'news', 'NEAR India',
        'blockchain', 'NEAR', 'developer', 'community events', 'updates',
        'localization', 'technology', 'South Asia'
    ],
    'yuvalxyz': [
        'magma', 'lava', 'lavanet', 'marketing', 'bd', 'community', 'infra',
        'data', 'Yuval', 'blockchain', 'NEAR', 'marketing', 'business development',
        'community engagement', 'infrastructure', 'data services'
    ],
    'yaircleper': [
        'founder', 'lava', 'lavanet', 'magma', 'cleper', 'Yair Cleper',
        'blockchain', 'NEAR', 'developer', 'founder', 'infrastructure',
        'technology', 'innovation', 'Lava Network'
    ],
    'thelittlesnft': [
        'nft', 'thelittles', 'nfts', 'design', 'The Littles NFT',
        'blockchain', 'NEAR', 'NFTs', 'digital art', 'collectibles',
        'crypto art', 'design', 'creative'
    ],
    'bodega_web3': [
        'bodega', 'community', 'game', 'dev', 'collectibles', 'nft', 'nfts',
        'Bodega Web3', 'blockchain', 'NEAR', 'gaming', 'developer',
        'collectibles', 'NFTs', 'community engagement', 'web3'
    ],
    'AlexSkidanov': [
        'founder', 'nearfounder', 'nearprotocol', 'dev', 'news', 'community',
        'Alex Skidanov', 'blockchain', 'NEAR', 'developer', 'founder',
        'technology', 'innovation', 'community engagement', 'updates'
    ],
    'NearTinkerUnion': [
        'nft', 'nfts', 'collection', 'NEAR Tinker Union', 'blockchain',
        'NEAR', 'NFTs', 'digital art', 'collectibles', 'community',
        'collaboration', 'creative', 'crypto art'
    ],
    '0xshadowbrown': [
        'chain', 'chainabstractor', 'chainabstraction', 'abstraction',
        'chainsig', 'chainsignatures', 'signature', 'dev', 'build',
        'Shadow Brown', 'blockchain', 'NEAR', 'developer', 'chain abstraction',
        'cryptography', 'innovation', 'technology'
    ],
    'quadron3stat3': [
        'founder', 'news', 'nearweek', 'community', 'nearfoundation',
        'nearprotocol', 'Quadrone Estate', 'blockchain', 'NEAR', 'founder',
        'news', 'community engagement', 'NEAR Foundation', 'updates'
    ],
    'joeespano_': [
        'joe', 'sharddog', 'dev', 'devrel', 'learn', 'tutorials', 'neardevhub',
        'Joe Espano', 'blockchain', 'NEAR', 'developer', 'developer relations',
        'learning', 'tutorials', 'education', 'community'
    ],
    'Freol': [
        'dev', 'learn', 'build', 'docs', 'nearprotocol', 'neardevhub',
        'developer', 'Freol', 'blockchain', 'NEAR', 'developer',
        'learning', 'documentation', 'education', 'technology'
    ],
    'ChrisDoNEARvan': [
        'founder', 'dev', 'learn', 'devrel', 'neardevhub', 'devhub',
        'nearfoundation', 'Chris Do NEARvan', 'blockchain', 'NEAR',
        'developer', 'founder', 'developer relations', 'learning',
        'education', 'technology'
    ],
    'NearMultiverse': [
        'metapool', 'marketing', 'community', 'latam', 'ecuador',
        'NEAR Multiverse', 'blockchain', 'NEAR', 'Meta Pool',
        'marketing', 'community engagement', 'Latin America', 'Ecuador',
        'staking'
    ],
    'BrazillianCare': [
        'brazil', 'metapool', 'latam', 'growth', 'community', 'founder',
        'Brazilian Care', 'blockchain', 'NEAR', 'Brazil', 'Latin America',
        'community engagement', 'growth', 'staking', 'Meta Pool'
    ],
    'waxnear': [
        'wax', 'community', 'news', 'influencer', 'Wax NEAR',
        'blockchain', 'NEAR', 'Wax blockchain', 'community engagement',
        'news', 'influencer', 'cryptocurrency'
    ],
    'Nearbigfinance': [
        'news', 'community', 'defi', 'NEAR Big Finance', 'blockchain',
        'NEAR', 'news', 'community engagement', 'DeFi', 'finance',
        'cryptocurrency', 'updates'
    ],
    'NearVietnamHub': [
        'nation', 'news', 'vietnam', 'asia', 'community', 'NEAR Vietnam Hub',
        'blockchain', 'NEAR', 'Vietnam', 'community engagement',
        'updates', 'localization', 'Southeast Asia'
    ],
    'NearKoreaHub': [
        'nation', 'news', 'korea', 'southkorea', 'asia', 'community',
        'NEAR Korea Hub', 'blockchain', 'NEAR', 'South Korea',
        'community engagement', 'updates', 'localization', 'East Asia'
    ],
    'near_intern': [
        'intern', 'degen', 'community', 'NEAR Intern', 'blockchain',
        'NEAR', 'internship', 'crypto enthusiast', 'community engagement',
        'learning', 'development'
    ],
    'lauranear': [
        'nearprotocol', 'nearfoundation', 'product', 'Laura NEAR',
        'blockchain', 'NEAR', 'product manager', 'technology',
        'development', 'innovation', 'NEAR Foundation'
    ],
    'NameSkyApp': [
        'dapp', 'domains', 'neardomains', 'dotnear', '.near', 'accounts',
        'wallets', 'buy', 'sell', 'trade', 'NameSky', 'blockchain',
        'NEAR', 'domain names', 'decentralized app', 'marketplace',
        'crypto domains'
    ],
    'ready_layer_one': [
        'metaverse', 'build', 'community', 'nft', 'content', 'sharddog',
        'Ready Layer One', 'blockchain', 'NEAR', 'metaverse', 'development',
        'community engagement', 'NFTs', 'content creation'
    ],
    'jarednotjerry1': [
        'sharddog', 'nft', 'dev', 'community', 'build', 'Jared Not Jerry',
        'blockchain', 'NEAR', 'developer', 'community engagement',
        'NFTs', 'development', 'technology'
    ],
    'ElCafeCartel': [
        'dapp', 'game', 'nft', 'dev', 'build', 'El Cafe Cartel',
        'blockchain', 'NEAR', 'decentralized app', 'gaming',
        'NFTs', 'developer', 'community', 'technology'
    ],
    'SecretSkellies': [
        'nft', 'collection', 'art', 'nfts', 'build', 'Secret Skellies',
        'blockchain', 'NEAR', 'NFTs', 'digital art', 'collectibles',
        'crypto art', 'development', 'creative'
    ],
    'ASAC_NFT': [
        'antisocial', 'apes', 'club', 'nft', 'nfts', 'art', 'build',
        'collection', 'ASAC NFT', 'blockchain', 'NEAR', 'NFTs',
        'digital art', 'collectibles', 'crypto art', 'community'
    ],
    'AlexAuroraDev': [
        'founder', 'ceo', 'aurora', 'dev', 'Alex Aurora Dev',
        'blockchain', 'Aurora', 'NEAR', 'developer', 'founder',
        'CEO', 'technology', 'innovation', 'development'
    ],
    'near_family': [
        'family', 'news', 'community', 'nft', 'trade', 'meme',
        'NEAR Family', 'blockchain', 'NEAR', 'community engagement',
        'NFTs', 'trading', 'memes', 'crypto'
    ],
    'CalimeroNetwork': [
        'calimero', 'network', 'privacy', 'data', 'chat', 'build', 'dev',
        'asia', 'ownership', 'Calimero Network', 'blockchain', 'NEAR',
        'privacy', 'data ownership', 'development', 'technology',
        'communication', 'Asia'
    ],
    'PagodaPlatform': [
        'pagoda', 'nearprotocol', 'nearfoundation', 'infra', 'dev', 'build',
        'Pagoda Platform', 'blockchain', 'NEAR', 'infrastructure',
        'developer', 'development', 'technology', 'innovation'
    ],
    'NEARBalkan': [
        'nation', 'news', 'community', 'balkans', 'europe', 'easteurope',
        'NEAR Balkan', 'blockchain', 'NEAR', 'Balkans', 'community engagement',
        'updates', 'localization', 'Eastern Europe'
    ],
    'BitteProtocol': [
        'bitte', 'wallet', 'ai', 'competition', 'Bitte Protocol',
        'blockchain', 'NEAR', 'wallet', 'artificial intelligence',
        'technology', 'competition', 'development'
    ],
    'NEAR__SF': [
        'siliconvalley', 'silicon', 'valley', 'sanfrancisco', 'san', 'francisco',
        'usa', 'america', 'devs', 'news', 'community', 'nation', 'NEAR SF',
        'blockchain', 'NEAR', 'San Francisco', 'USA', 'developers',
        'community engagement', 'updates', 'technology'
    ],
    'DeAlmeidaDavid': [
        'validator', 'ai', 'onchain', 'fetchai', 'panda', 'pandateam',
        'David De Almeida', 'blockchain', 'NEAR', 'validator',
        'artificial intelligence', 'on-chain data', 'developer',
        'technology', 'Panda Team'
    ],
    'NEAR_China': [
        'china', 'nation', 'asia', 'community', 'NEAR China',
        'blockchain', 'NEAR', 'community engagement', 'updates',
        'localization', 'development', 'technology'
    ],
    'NEARProtocolJP': [
        'japan', 'nearjapan', 'asia', 'dev', 'news', 'community',
        'NEAR Protocol JP', 'blockchain', 'NEAR', 'Japan', 'developer',
        'community engagement', 'updates', 'localization'
    ],
    'SweatEconomy': [
        'sweat', 'economy', 'walktoearn', 'sweattoearn', 'dev', 'build',
        'Sweat Economy', 'blockchain', 'NEAR', 'move to earn',
        'fitness', 'cryptocurrency', 'development', 'health', 'wellness'
    ],
    'LearnNear': [
        'learn', 'dev', 'build', 'educate', 'Learn NEAR',
        'blockchain', 'NEAR', 'education', 'developer', 'learning',
        'development', 'resources', 'technology'
    ],
    'near_insider': [
        'news', 'learn', 'community', 'build', 'data', 'onchain',
        'NEAR Insider', 'blockchain', 'NEAR', 'updates', 'learning',
        'community engagement', 'on-chain data', 'development'
    ],
    'awesome_near': [
        'news', 'data', 'dapps', 'dappradar', 'catalogue', 'nearprotocol',
        'docs', 'community', 'Awesome NEAR', 'blockchain', 'NEAR',
        'applications', 'directory', 'documentation', 'community',
        'resources'
    ],
    'LinearProtocol': [
        'layer', 'omni', 'chain', 'liquid', 'stake', 'restake', 'abstracted',
        'chainabstraction', 'signatures', 'Linear Protocol', 'blockchain',
        'NEAR', 'layer protocol', 'chain abstraction', 'staking',
        'liquid staking', 'cryptography', 'technology'
    ],
    'Cameron_Dennis_': [
        'news', 'influencer', 'cameron', 'dev', 'thebafnetwork',
        'nearprotocol', 'community', 'Cameron Dennis', 'blockchain',
        'NEAR', 'developer', 'influencer', 'community engagement',
        'BAF Network', 'technology'
    ],
    'ParasHQ': [
        'nft', 'marketplace', 'nfts', 'paras', 'trade', 'buy', 'sell',
        'Paras HQ', 'blockchain', 'NEAR', 'NFTs', 'marketplace',
        'trading', 'digital art', 'collectibles', 'crypto art'
    ],
    'NEAR_Blockchain': [
        'news', 'community', 'trend', 'influencer', 'NEAR Blockchain',
        'blockchain', 'NEAR', 'news', 'community engagement',
        'updates', 'trends', 'technology', 'information'
    ],
    'nekotoken_xyz': [
        'meme', 'memecoins', 'neko', 'token', 'Neko Token',
        'blockchain', 'NEAR', 'cryptocurrency', 'memecoin', 'crypto asset',
        'community', 'cat-themed'
    ],
    'NearFrancais': [
        'french', 'nation', 'europe', 'francais', 'france', 'news', 'community',
        'NEAR Fran√ßais', 'blockchain', 'NEAR', 'France', 'French language',
        'community engagement', 'updates', 'localization', 'Europe'
    ],
    'billybones1_': [
        'founder', 'influencer', 'news', 'build', 'dev', 'Billy Bones',
        'blockchain', 'NEAR', 'developer', 'founder', 'influencer',
        'technology', 'development', 'community engagement'
    ],
    'FewandFarNFT': [
        'nft', 'nfts', 'community', 'art', 'Few and Far NFT',
        'blockchain', 'NEAR', 'NFTs', 'digital art', 'collectibles',
        'crypto art', 'marketplace', 'community'
    ],
    'NEARFoundation': [
        'nearfoundation', 'nearprotocol', 'news', 'community', 'dao',
        'NEAR Foundation', 'blockchain', 'NEAR', 'news', 'community engagement',
        'decentralized autonomous organization', 'development', 'updates'
    ],
}


--- File: ./scrapers/__init__.py ---


--- File: ./scrapers/tweets/tweet_fetcher_config.yaml ---
api_endpoint: 'http://localhost:8080/api/v1/data/twitter/tweets/recent' 
headers:
  accept: 'application/json'
  Content-Type: 'application/json'

# Query settings
account: 'NEARMobile_app'  # The account whose followed list we want to fetch
tweets_per_request: 70

# Add start_date and end_date
start_date: '2024-10-8'
end_date: '2024-11-8'
days_per_iteration: 7

# File settings
data_directory: 'data/NEARMobileAppFollowedAccounts'

# Timing settings
retry_delay: 1111  # 16 minutes in seconds
request_delay: 21  # 15 seconds between requests

# Logging settings
log_level: 'INFO'
log_format: '%(asctime)s - %(levelname)s - %(message)s'

# NEW
max_retries: 5
request_timeout: 60


--- File: ./scrapers/tweets/tweet_fetcher.py ---
import requests
import os
import yaml
from datetime import datetime, timedelta
from dotenv import load_dotenv
import time
import logging
import json
from tweet_service import setup_logging, ensure_data_directory, save_all_tweets, create_tweet_query

def load_config():
    dir_path = os.path.dirname(os.path.realpath(__file__))
    config_path = os.path.join(dir_path, 'tweet_fetcher_config.yaml')
    with open(config_path, 'r') as file:
        return yaml.safe_load(file)

def save_state(state, api_calls_count, records_fetched, all_tweets):
    state_data = {
        'last_known_state': state,
        'api_calls_count': api_calls_count,
        'records_fetched': records_fetched,
        'all_tweets_sample': all_tweets[:7]  # Guarda una muestra de los primeros 10 tweets para visibilidad
    }
    with open('last_known_state_detailed.json', 'w') as f:
        json.dump(state_data, f, indent=4)

def load_state():
    try:
        with open('last_known_state_detailed.json', 'r') as f:
            return json.load(f).get('last_known_state', {})
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def exponential_backoff(attempt, base=60):
    return base * (2 ** attempt)  # Backoff exponencial: retraso base * 2^intento

def fetch_tweets(config):
    start_date = datetime.strptime(config['start_date'], '%Y-%m-%d').date()
    end_date = datetime.strptime(config['end_date'], '%Y-%m-%d').date()
    days_per_iteration = config['days_per_iteration']

    # Lista de cuentas de Twitter de los equipos de La Liga 2024-2025
    accounts = [
        'NEARMobile_app', #nearmobile.app #nearmobile #nearmobileapp #wallet #nearwallet #noncustodial #selfcustodial #peersyst
        'NEARMintern', #intern #NEARMobile #dapps
        'nearblocks', #explorer #blocks #onchain #data #explore #nearblock #txhash #transactions
        'NEARProtocol', #nearprotocol #near #nearfoundation #illia #news
        'finance_ref',#ref #reffinance #dapp #swap #pools #liquiditypools #trade #amm #amms #usdc #usdt #frax #top #tvl
        'ref_intern', #ref #intern #dapp #swap #pools #liquiditypools #trade #amm #amms #usdc #usdt #frax #top #tvl
        'meta_pool', #pool #pools #stake #stNEAR #mpDAO #dao #reStake #liquid #tvl #dapp
        'burrow_finance', #lending #lend #borrow #burrow #usdc #usdt #frax #stake #pools #tvl #dapp
        'beepopula', #community #dapp #privacy #onchain #social
        'DeltaBotTeam', #dca #trade #gachapon #airdrop #swing #bots #ai #stablecoin #usdc #usdt #aibot #tradebot #tokens #auto #dapp
        'shitzuonnear', #dogshit #shitzu #meme #stake #validator #dev #build
        'memedotcooking', #meme #memecoin #launchpad #buy #sell #rug #meme.cooking #cook #memecooking #shitzu #dogshit
        'sharddog', #nft #nfts #mint #sharddog #community #build
        'nadabots', #certificate #did #proof #humanproof #id #bots #nada
        'potlock_', #funding #ai #design #potlock #pot #startup
        'JumpDeFi', #jump #defi #stake #nft
        'TokenBridgeApp', #bridge #swap #transfer #crosschain #solana #binance #arbitrum #token
        'tknhomes', #token #marketplace #launchpad #meme #memecoin
        'NEARDevHub', #dev #build #ai #chain #onnear #devrel #tutorial
        'NEARdevs', #dev #build #ai #chain #onnear
        'ilblackdragon', #founder #illia #dev #build #nearceo #boss #blackdragon #nearprotocol #nearfoundation
        'GNearAi', #meme #ai
        'vxyz_near', #community
        'NEARQuant', #community #news #alpha
        'taostats', #ai #bittensor #masaAI #web3
        'nearcatalog', #community #dapps #dappradar #projects #news #trends
        'marior_dev', #community #dev #shitzu #orderly #futures #derivatives
        'SKYTONET_', #community #mod #ambassador #ref #shitzu #meme #memedotcooking
        'invokerlabs', #dev #build #nearblocks
        'Nearsend_io', #dev #nep #send #invokerlabs #bulk #transactions
        'questflow', #project #dapp #ai #agents
        'DayTrader888', #growth #veax #dex #degen
        'NearKatToken', #meme #memecoin #token #kat #cat
        'ai_pgf', #potlock #ai #funding #agi
        'hotdao_', #hot #herewallet #dao #telegram
        'p_volnov', #hotdao #herewallet #founder #dev
        'ThunderHoodlab', #meme #dex #marketplace #launchpad #trade #deploy
        'getmasafi', #ai #agents #scrape #data #twitterscrape #discord #telegram #web #webscrape #mine #bittensor #tao
        'growthmate_xyz', #data #onchain #dapps #trends #community
        'NearGamesDAO', #community #game #gamers #dao #play
        'SailGPESP', #sailgp #nearspain #nearesp #nearpartners #nearsports
        'elm_money', #founder #ai #community #neardc #digital #marketing #dao #aurora #apps #games
        'KagemniKarimu', #dev #devrel #lava #magma #lavanet #rpc #data #apps #host #storage
        'xgilxgil', #dev #lava #lavanet #rpc #magma
        'magmadevs', #dev #lava #lavanet #magma
        'consensus128', #marketing #community #lava #rpc
        'theinterestedr1', #founder #cto #lava #dev #build
        'NimrodxLava', #dev #lava #r&d #magma
        'beanonnear', #meme #memecoin #token #mrbean #stake #nft #ref #jump
        'fraxfinance', #stable #coin #token #lend #borrow #defi #fiat #stake #sfrax
        '_Curmello', #community #designer #graphic #content #creator #cm #news
        'intelnear', #meme #memecoins #token #ai #intel
        'near_ai', #ai #machine #code #dev
        'pauldgreat1234', #otto #nigeria #octopus #omni #dfinity #btc #uwon
        'Ottochain_', #otto #token #omnity #evm #cosmos #cosmossdk
        'OctopusNation_', #octopus #network #restake #stake #cosmos #cosmossdk
        'nearuaguild', #ukraine #ucrania #nearuaguild #dev #community #nation
        'i_moskalenko_', #ukraine #uaguild #community #content #creator
        'inscriptionneat', #neat #token #supportedtoken #ai #inscription #rollup #scale
        'buidlnear', #vikthebuilder #dev #components #nearprotocol #bitte
        'David___Mo', #nearprotocol #nearfoundation #creative #marketing #campaign #strategy #davidmo
        'Waliyullah99', #spaces #spacehost #host #chill #xspace
        'ChillonNear', #meme #memecoin #chill #token
        'near_punks', #punks #nfts #nft #largestNFTcollection #npunks #nearkingdoms
        'nearkingdoms', #game #nft #gaming #nearkingdoms #nearpunks #punks
        'maxtonear', #founder #nearpunks #nearkingdoms #game #punks #nft #nfts #dev
        'near_brazil', #community #brazil #brasil #news #portugues #noticias #latam
        'NearlendDao', #capitalmarket #dao #defi #lending #lend #stake #apy #liquidation #stablecoins
        'NEARArgentina', #argentina #latam #community #news #espa√±ol #comunidad
        'Near_ES', #espa√±a #espa√±ol #latam #community #news #comunidad
        'Milly_R06', #espa√±a #latam #espa√±ol #news #cm
        'Freyja_GoddessM', #women #nearwomen #womenweb3
        'NearGlobeDAO', #nations #world #nearregional #communities #countries #globe #nearglobe
        'ThaLeonard_', #cm #projectmanager #marketing #strategy #neardc #freelancers #nearprotocol #community
        'NearHausaa', #nation #community #hausaa #language #nigeria
        'USM_eme', #meme #memecoin #token #usm
        'Lonkonnear', #meme #lonk #memecoin #token
        'theomnidao', #build #nft #nearprotocol #omni #dao #nearfoundation
        'dragonisnear', #meme #memecoin #blackdragon #dragon #token
        'dragonbot_xyz', #meme #memecoin #telegram #bot #token
        'LuloBank', #mint #nearmint #lulo #lulox #stablecoin #token #minter #nep141 #dev #colombia #latam
        'NearMexico', #mexico #latam #community #nation #news
        'srpuuul', #memes #intern #metapool #stNEAR #mpDAO #meta_pool
        'stakecito', #cosmos #validator #cosmossdk #delegator
        'staderlabs', #st #token #neartoken #stader #stake #liquidstake #liquid
        'Masi_DN', #dev #build #onchain #data #news
        'NearnftWG', #nft #nearnft #nftwork #nftworkgroup #neardc #sharddog #nearverse
        'SatJanserik1986', #community #news #jsat
        'ThePiVortex', #owen #neardevrel #dev #devrel #community #news #build #xspace
        'pikespeak_ai', #dev #explorer #pikespeak #ai #build #onchain
        'ekuzyakov', #evgeny #founder #fastnear #nearsocial #social #nearprotocol #proximity #labs #dev #build
        'fast_near', #infra #rpc #api #dev #build
        'proximityfi', #dev #learn #build #ai #chainsignatures #chainabstraction #sighnatures #abstraction
        'zacodil', #community #news #ai #dev #zavodil #validator #vadim #infra
        'sal_data', #dev #data #stake #nearprotocol #onchain #build #ambassador #community
        'MeteorWallet', #wallet #competition #meteor
        'TheChels001', #mitte #nft #community #ambassador #content
        'GUS_DAO', #nearweek #week #news #community #dao #linkdrop #openweb #gus
        'Rous_cripto', #latam #metapool #argentina #content #community #intern #customersupport #spaces #xspaces
        'dillon_near', #nft #pfp #mintbase #community #capybara
        'monzaNFT', #nft #community #nearforest #cm #community #marketing #near_at_night #xspace #space
        'OpenForest_', #rwa #onchain #carbon #consensuslayer #layer #defi #stake #lending #bonds #token
        'edgevideoai', #stream #space #video #fast #revenue #edge #ai
        'pironidi', #didier #defi #dev #growth #founder #pikespeak #ref #reffinance
        'NEARChainStatus', #onchain #data #validator #infra #community #news #devrel #updates #status
        'marrowng', #metapool #marketing #founder #community #latam #espa√±ol
        'noahmajor1776', #nono #nearmaxi #content #creator #community #news #dev
        'NEAR_Arabic', #nation #arab #language #community
        'EsNearEs', #espa√±ol #latam #noticias #news #community
        'NearPositive', #community #news
        'Near_Colombia', #latam #nation #espa√±ol #colombia #news #community
        'MITTE_gg', #nft #dapp #nftmarketplace #trade #trading
        'EvgenSkydan', #ukraine #ucrania #nearua #nearuaguild #neardc #explorer #news #dev #onchain #community
        'jjyuannear', #jerry #yuannear #nearusa #usa #banyan #founder #news #dev #devrel #community
        'Banyan_NEAR', #build #dev #project #banyan #nearprotocol #develop
        'SourceDegen', #degen #community
        'rendal73', #degen #community
        'n0trdame', #degen #community
        'here_wallet', #wallet #competition #hot #telegram
        'cosmos', #cosmos #cosmossdk #ibc #consensuslayer #layer #atom
        'axelar', #bridge #axelar #token
        'EvmosOrg', #evm #network #evmos
        'osmosiszone', #osmosis #cosmos #atom
        'near_malaysia', #nation #community #malaysia #malasia #asia #community
        'ekosubagyo', #maxone #metapool #community #ambassador
        'alannetwork_', #metapool #latam #openweb #dev
        'swisshustler', #nearprotocol #swiss #nearfoundation
        'Mikikin8', #defi #founder #dev #defishards #shards 
        'DeFiShardsxyz', #defi #sharding #shards defishards #nft #docs #liquid #stake
        'mraltantutar', #nearprotocol #nearfoundation #georgia #founder #dev #chain #chainabstracted #signatures
        'aescobarindo', #escobar #reffinance #ref #dapdap #dex #dev #marketing #community #founder #playember
        'chronear', #dev #build #chain #chainabstraction #abstraction #signatures #chainsig
        'NearIndia', #india #asia #nation #community #dev #news
        'yuvalxyz', #magma #lava #lavanet #marketing #bd #community #infra #data
        'yaircleper', #founder #lava #lavanet #magma #cleper
        'thelittlesnft', #nft #thelittles #nfts #design
        'bodega_web3', #bodega #community #game #dev #collectibles #nft #nfts
        'AlexSkidanov', #founder #nearfounder #nearprotocol #dev #news #community
        'NearTinkerUnion', #nft #nfts #collection
        '0xshadowbrown', #chain #chainabstractor #chainasbtraction #abstraction #chainsig #chainsignatures #signature #dev #build
        'quadron3stat3', #founder #news #nearweek #community #nearfoundation #nearprotocol
        'joeespano_', #joe #sharddog #dev #devrel #learn #tutorials #neardevhub
        'Freol', #dev #learn #build #docs #nearprotocol #neardevhub #developer
        'ChrisDoNEARvan', #founder #dev #learn #devrel #neardevhub #devhub #nearfoundation
        'NearMultiverse', #metapool #marketing #community #latam #ecuador
        'BrazillianCare', #brazil #metapool #latam #growth #community #founder
        'waxnear', #wax #community #news #influncer
        'Nearbigfinance', #news #community #defi
        'NearVietnamHub', #nation #news #vietnam #asia #community
        'NearKoreaHub', #nation #news #korea #southkorea #asia #community
        'near_intern', #intern #degen #community
        'lauranear', #nearprotocol #nearfoundation #product
        'NameSkyApp', #dapp #domains #neardomains #dotnear #.near #accounts #wallets #buy #sell #trade
        'ready_layer_one', #metaverse #build #community #nft #content #sharddog
        'jarednotjerry1', #sharddog #nft #dev #community #build
        'ElCafeCartel', #dapp #game #nft #dev #build
        'SecretSkellies', #nft #collection #art #nfts #build
        'ASAC_NFT', #antisocial #apes #club #nft #nfts #art #build #collection
        'AlexAuroraDev', #founder #ceo #aurora #dev
        'near_family', #family #news #community #nft #trade #meme
        'CalimeroNetwork', #calimero #network #privacy #data #chat #build #dev #asia #ownership
        'PagodaPlatform', #pagoda #nearprotocol #nearfoundation #infra #dev #build
        'NEARBalkan', #nation #news #community #balkans #europe #easteurope #news #balkans 
        'BitteProtocol', #bitte #wallet #ai #competition
        'NEAR__SF', #siliconvalley #silicon #valley #sanfrancisco #san #francisco #usa #america #devs #news #community #nation
        'DeAlmeidaDavid', #validator #ai #onchain #fetchai #panda #pandateam
        'NEAR_China', #china #nation #asia #community
        'NEARProtocolJP', #japan #nearjapan #asia #dev #news #community
        'SweatEconomy', #sweat #economy #walktoearn #sweattoern #dev #build
        'LearnNear', #learn #dev #build #educate
        'near_insider', #news #learn #community #build #data #onchain
        'awesome_near', #news #data #dapps #dappsradar #catalogue #nearprotocol #docs #community
        'LinearProtocol', #layer #omni #chain #liquid #stake #restake #abstracted #chainabstraction #signatures
        'Cameron_Dennis_', #news #influencer #cameron #dev #thebafnetwork #nearprotocol #community
        'ParasHQ', #nft #marketplace #nfts #paras #trade #buy #sell
        'NEAR_Blockchain', #news #community #trend #influencer
        'nekotoken_xyz', #meme #memecoins #neko #token
        'NearFrancais', #french #nation #europe #francais #frances #news #community
        'billybones1_' #founder #influencer #news #build #dev
        'FewandFarNFT', #nft #nfts #community #art
        'NEARFoundation', #nearfoundation #nearprotocol #news #community #dao

    ]

    for account in accounts:
        logging.info(f"Fetching tweets for account: {account}")
        current_date = end_date

        # Crear un directorio de datos para cada cuenta
        account_data_directory = os.path.join(config['data_directory'], account)
        ensure_data_directory(account_data_directory)

        api_calls_count = 0
        records_fetched = 0
        all_tweets = []

        while current_date >= start_date:
            success = False
            attempts = 0

            while not success and attempts < config['max_retries']:
                iteration_start_date = current_date - timedelta(days=days_per_iteration)
                day_before = max(iteration_start_date, start_date - timedelta(days=1))

                # Crear el query para la cuenta actual
                query = create_tweet_query(account, day_before, current_date)
                print(query)
                request_body = {"query": query, "count": config['tweets_per_request']}

                try:
                    response = requests.post(
                        config['api_endpoint'],
                        json=request_body,
                        headers=config['headers'],
                        timeout=config['request_timeout']
                    )
                    api_calls_count += 1

                    if response.status_code == 200:
                        response_data = response.json()
                        if response_data and 'data' in response_data and response_data['data'] is not None:
                            tweets = response_data['data']
                            all_tweets.extend(tweets)
                            num_tweets = len(tweets)
                            records_fetched += num_tweets
                            logging.info(f"Fetched {num_tweets} tweets for {account} from {day_before} to {current_date}.")
                            success = True
                        else:
                            logging.warning(f"No tweets fetched for {account} from {day_before} to {current_date}. Retrying after delay...")
                            time.sleep(config['request_delay'])
                            attempts += 1
                    elif response.status_code == 429 or response.status_code == 500:
                        if response.status_code == 429:
                            logging.warning("Rate-limited. Retrying after delay...")
                            time.sleep(exponential_backoff(attempts, base=config['retry_delay']))
                            attempts += 1
                        elif response.status_code == 500:
                            logging.warning("500 Error. Retrying after delay...")
                            time.sleep(exponential_backoff(attempts, base=config['retry_delay']))
                            attempts += 1
                    else:
                        logging.error(f"Failed to fetch tweets: {response.status_code}")
                        break

                except requests.exceptions.RequestException as e:
                    logging.error(f"Request failed: {e}")
                    time.sleep(exponential_backoff(attempts, base=config['retry_delay']))
                    attempts += 1

            if not success:
                logging.error(f"Failed after {attempts} attempts for {account} from {day_before} to {current_date}")

            # Guardar el estado si es necesario
            save_state({'current_date': current_date.strftime('%Y-%m-%d'), 'account': account}, api_calls_count, records_fetched, all_tweets)
            current_date -= timedelta(days=days_per_iteration)
            time.sleep(config['request_delay'])

        # Guardar todos los tweets de la cuenta actual
        save_all_tweets(all_tweets, account_data_directory, f"from:{account}")

        logging.info(f"Finished fetching tweets for account: {account}. Total API calls: {api_calls_count}. Total records fetched: {records_fetched}")

if __name__ == "__main__":
    load_dotenv()
    config = load_config()
    setup_logging(config['log_level'], config['log_format'])
    fetch_tweets(config)

--- File: ./scrapers/tweets/README.md ---
# Getting Started with the Tweet Fetcher

## Introduction
The Tweet Fetcher is a Python script designed for developers to fetch tweets from a specified Twitter account within a given date range. This README provides instructions on setting up and using the Tweet Fetcher.

## Prerequisites
- Conda installed on your system.
- An environment set up using the provided `environment.yml` file. To set up the environment, run:
  ```bash
  conda env create -f environment.yml
  ```
  Activate the environment with:
  ```bash
  conda activate awesome-masa
  ```

## Configuration
Before running the script, you need to configure it to specify the API endpoint, query parameters, and other settings.

1. **API Settings**: Specify the API endpoint and headers for the request.
2. **Query Settings**: Define the query for fetching tweets, including the Twitter account and the number of tweets per request.
3. **Date Range**: Set the `start_date` and `end_date` for the period from which you want to fetch tweets.
4. **Iteration Settings**: Adjust `days_per_iteration` to control how many days' worth of tweets are fetched per iteration within the date range.
5. **File and Logging Settings**: Specify the directory for saving fetched tweets and configure logging preferences.

Refer to the configuration file section for more details:

```1:25:examples/tweets/tweet_fetcher_config.yaml
# API settings
api_endpoint: 'http://localhost:8080/api/v1/data/twitter/tweets/recent'
headers:
  accept: 'application/json'
  Content-Type: 'application/json'

# Query settings
query: 'from:milesdeutscher'
tweets_per_request: 100

# Add start_date and end_date
start_date: '2023-07-24'
end_date: '2024-07-24'
days_per_iteration: 10

# File settings
data_directory: 'data'

# Timing settings
retry_delay: 960  # 16 minutes in seconds
request_delay: 15  # 15 seconds between requests

# Logging settings
log_level: 'INFO'
log_format: '%(asctime)s - %(levelname)s - %(message)s'
```


## Running the Script
To fetch tweets, follow these steps:

1. Navigate to the script's directory in your terminal.
2. Run the script using Python:
   ```bash
   python tweet_fetcher.py
   ```

## How It Works
The script performs the following steps:

1. Loads the configuration from `tweet_fetcher_config.yaml`.
2. Fetches tweets based on the specified query and date range.
3. Saves the fetched tweets in the specified directory as a JSON file.

Refer to the service module for more details on the functions used:

```1:23:examples/tweets/tweet_service.py
import json
import logging
import os
import time
from datetime import datetime

def setup_logging(log_level, log_format):
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {log_level}')
    logging.basicConfig(level=numeric_level, format=log_format)

def ensure_data_directory(directory):
    os.makedirs(directory, exist_ok=True)

def save_all_tweets(tweets, data_directory):
    filename = f'{data_directory}/all_tweets_{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.json'
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(tweets, file, ensure_ascii=False, indent=2)
    logging.info(f"All tweets saved to {filename}")

def create_tweet_query(hashtag, start_date, end_date):
    return f"({hashtag} until:{end_date.strftime('%Y-%m-%d')} since:{start_date.strftime('%Y-%m-%d')})"
```


## Output
The fetched tweets are saved in the `data_directory` specified in the configuration file. Each file is named with a timestamp to ensure uniqueness.

## Logging
The script logs its progress and any errors encountered during execution. You can adjust the log level and format in the configuration file to suit your needs.

## Customization
You can customize the script by modifying the configuration file or extending the Python scripts to add new functionality or adjust existing features.

For any issues or further assistance, please refer to the inline documentation within the codebase.

--- File: ./scrapers/tweets/tweet_service.py ---
import json
import logging
import os
import time
from datetime import datetime

def setup_logging(log_level, log_format):
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {log_level}')
    logging.basicConfig(level=numeric_level, format=log_format)

def ensure_data_directory(directory):
    os.makedirs(directory, exist_ok=True)

def save_all_tweets(tweets, data_directory, query):
    query_target = query.split(':')[1].rstrip(')')
    filename = f'{data_directory}/{query_target}_{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.json'
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(tweets, file, ensure_ascii=False, indent=2)
    logging.info(f"All tweets saved to {filename}")

def create_tweet_query(account, start_date, end_date):
    return f"(from:{account} until:{end_date.strftime('%Y-%m-%d')} since:{start_date.strftime('%Y-%m-%d')})"


--- File: ./scrapers/scrapeFollowing/tweet_fetcher_config.yaml ---
# API settings
api_endpoint: 'http://localhost:8080/api/v1/data/twitter/tweets/recent' 
headers:
  accept: 'application/json'
  Content-Type: 'application/json'

# Query settings
account: 'NEARMobile_app'  # The account whose followed list we want to fetch
count_per_request: 30

# Add start_date and end_date
start_date: '2024-10-8'
end_date: '2024-11-8'
days_per_iteration: 2

# File settings
data_directory: 'data/NEARMobileAppFollowedAccounts'

# Timing settings
retry_delay: 1111  # 16 minutes in seconds
request_delay: 33  # 15 seconds between requests

# Logging settings
log_level: 'INFO'
log_format: '%(asctime)s - %(levelname)s - %(message)s'

# NEW
max_retries: 33
request_timeout: 60


--- File: ./scrapers/scrapeFollowing/tweet_fetcher.py ---
import requests
import os
import yaml
import time
import logging
import json
from dotenv import load_dotenv
from tweet_service import setup_logging, ensure_data_directory, save_followed_accounts

def load_config():
    dir_path = os.path.dirname(os.path.realpath(__file__))
    config_path = os.path.join(dir_path, 'tweet_fetcher_config.yaml')
    with open(config_path, 'r') as file:
        return yaml.safe_load(file)

def save_state(state, api_calls_count, records_fetched, followed_accounts):
    state_data = {
        'last_known_state': state,
        'api_calls_count': api_calls_count,
        'records_fetched': records_fetched,
        'followed_accounts_sample': followed_accounts[:7]  # Save a sample for visibility
    }
    with open('last_known_state_detailed.json', 'w') as f:
        json.dump(state_data, f, indent=4)

def load_state():
    try:
        with open('last_known_state_detailed.json', 'r') as f:
            return json.load(f).get('last_known_state', {})
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def exponential_backoff(attempt, base=60):
    return base * (2 ** attempt)  # Exponential backoff

def fetch_followed_accounts(config):
    account = config['account']
    logging.info(f"Fetching followed accounts for: {account}")

    api_calls_count = 0
    records_fetched = 0
    followed_accounts = []
    cursor = -1  # Default cursor to start pagination

    success = False
    attempts = 0

    while not success and attempts < config['max_retries']:
        # Construct URL with query parameters
        url = f"{config['api_endpoint']}?screen_name={account}&count={config['count_per_request']}&cursor={cursor}"

        try:
            # Perform GET request
            response = requests.get(
                url,
                headers=config['headers'],
                timeout=config['request_timeout']
            )
            api_calls_count += 1

            if response.status_code == 200:
                response_data = response.json()
                if response_data and 'users' in response_data:
                    users = response_data['users']
                    followed_accounts.extend(users)
                    num_followed = len(users)
                    records_fetched += num_followed
                    logging.info(f"Fetched {num_followed} followed accounts for {account}.")

                    # Update cursor for pagination
                    cursor = response_data.get('next_cursor', 0)
                    
                    # Stop if there are no more users to fetch
                    if cursor == 0:
                        success = True
                else:
                    logging.warning(f"No followed accounts fetched for {account}. Retrying after delay...")
                    time.sleep(config['request_delay'])
                    attempts += 1
            elif response.status_code == 429 or response.status_code == 500:
                if response.status_code == 429:
                    logging.warning("Rate-limited. Retrying after delay...")
                    time.sleep(exponential_backoff(attempts, base=config['retry_delay']))
                    attempts += 1
                elif response.status_code == 500:
                    logging.warning("500 Error. Retrying after delay...")
                    time.sleep(exponential_backoff(attempts, base=config['request_delay']))
                    attempts += 1
            else:
                logging.error(f"Failed to fetch followed accounts: {response.status_code}")
                break

        except requests.exceptions.RequestException as e:
            logging.error(f"Request failed: {e}")
            time.sleep(exponential_backoff(attempts, base=config['retry_delay']))
            attempts += 1

    if not success:
        logging.error(f"Failed after {attempts} attempts for {account}")

    # Save the followed accounts
    ensure_data_directory(config['data_directory'])
    save_followed_accounts(followed_accounts, config['data_directory'], account)

    # Save the state if necessary
    save_state({'account': account}, api_calls_count, records_fetched, followed_accounts)

    logging.info(f"Finished fetching followed accounts for {account}. Total API calls: {api_calls_count}. Total records fetched: {records_fetched}")

if __name__ == "__main__":
    load_dotenv()
    config = load_config()
    setup_logging(config['log_level'], config['log_format'])
    fetch_followed_accounts(config)


--- File: ./scrapers/scrapeFollowing/README.md ---
# Getting Started with the Tweet Fetcher

## Introduction
The Tweet Fetcher is a Python script designed for developers to fetch tweets from a specified Twitter account within a given date range. This README provides instructions on setting up and using the Tweet Fetcher.

## Prerequisites
- Conda installed on your system.
- An environment set up using the provided `environment.yml` file. To set up the environment, run:
  ```bash
  conda env create -f environment.yml
  ```
  Activate the environment with:
  ```bash
  conda activate awesome-masa
  ```

## Configuration
Before running the script, you need to configure it to specify the API endpoint, query parameters, and other settings.

1. **API Settings**: Specify the API endpoint and headers for the request.
2. **Query Settings**: Define the query for fetching tweets, including the Twitter account and the number of tweets per request.
3. **Date Range**: Set the `start_date` and `end_date` for the period from which you want to fetch tweets.
4. **Iteration Settings**: Adjust `days_per_iteration` to control how many days' worth of tweets are fetched per iteration within the date range.
5. **File and Logging Settings**: Specify the directory for saving fetched tweets and configure logging preferences.

Refer to the configuration file section for more details:

```1:25:examples/tweets/tweet_fetcher_config.yaml
# API settings
api_endpoint: 'http://localhost:8080/api/v1/data/twitter/tweets/recent'
headers:
  accept: 'application/json'
  Content-Type: 'application/json'

# Query settings
query: 'from:milesdeutscher'
tweets_per_request: 100

# Add start_date and end_date
start_date: '2023-07-24'
end_date: '2024-07-24'
days_per_iteration: 10

# File settings
data_directory: 'data'

# Timing settings
retry_delay: 960  # 16 minutes in seconds
request_delay: 15  # 15 seconds between requests

# Logging settings
log_level: 'INFO'
log_format: '%(asctime)s - %(levelname)s - %(message)s'
```


## Running the Script
To fetch tweets, follow these steps:

1. Navigate to the script's directory in your terminal.
2. Run the script using Python:
   ```bash
   python tweet_fetcher.py
   ```

## How It Works
The script performs the following steps:

1. Loads the configuration from `tweet_fetcher_config.yaml`.
2. Fetches tweets based on the specified query and date range.
3. Saves the fetched tweets in the specified directory as a JSON file.

Refer to the service module for more details on the functions used:

```1:23:examples/tweets/tweet_service.py
import json
import logging
import os
import time
from datetime import datetime

def setup_logging(log_level, log_format):
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {log_level}')
    logging.basicConfig(level=numeric_level, format=log_format)

def ensure_data_directory(directory):
    os.makedirs(directory, exist_ok=True)

def save_all_tweets(tweets, data_directory):
    filename = f'{data_directory}/all_tweets_{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.json'
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(tweets, file, ensure_ascii=False, indent=2)
    logging.info(f"All tweets saved to {filename}")

def create_tweet_query(hashtag, start_date, end_date):
    return f"({hashtag} until:{end_date.strftime('%Y-%m-%d')} since:{start_date.strftime('%Y-%m-%d')})"
```


## Output
The fetched tweets are saved in the `data_directory` specified in the configuration file. Each file is named with a timestamp to ensure uniqueness.

## Logging
The script logs its progress and any errors encountered during execution. You can adjust the log level and format in the configuration file to suit your needs.

## Customization
You can customize the script by modifying the configuration file or extending the Python scripts to add new functionality or adjust existing features.

For any issues or further assistance, please refer to the inline documentation within the codebase.

--- File: ./scrapers/scrapeFollowing/tweet_service.py ---
import json
import logging
import os
from datetime import datetime

def setup_logging(log_level, log_format):
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError(f'Invalid log level: {log_level}')
    logging.basicConfig(level=numeric_level, format=log_format)

def ensure_data_directory(directory):
    os.makedirs(directory, exist_ok=True)

# Updated to save followed accounts
def save_followed_accounts(followed_accounts, data_directory, account_name):
    filename = f'{data_directory}/{account_name}_followed_accounts_{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.json'
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(followed_accounts, file, ensure_ascii=False, indent=2)
    logging.info(f"Followed accounts saved to {filename}")

# The query function is not used for followed accounts but retained for completeness
def create_tweet_query(account, start_date, end_date):
    return f"(from:{account})"


--- File: ./src/__init__.py ---
from . import agent

--- File: ./src/agent/core/config.py ---
# Existing imports and configurations
import logging
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# URLs for data loading
# TODO: Extend to other data types, Web, Discord, Telegram, YouTube, and Podcast
DATA_URLS = [
    "data/NEARMobileAppFollowedAccounts",
]


--- File: ./src/agent/TWITTER.md ---
1. Starting point: JSON file (`data/tweets.json`)
```json
[
  {
    "ConversationID": "1775858583231439117",
    "Username": "Trader_XO",
    "Text": "@MaxController Got cut at $5 \n\nBought back in at $1 and sold again at 1.90",
    // ... other fields ...
  },
  {
    "ConversationID": "1815797777462616202",
    "Username": "Trader_XO",
    "Text": "@TraderMagus Grifters are efficient that much I can tell you for free \n\nParticularly the ones who have found their balls again after a 15k move up off the lows",
    // ... other fields ...
  }
]
```

2. After `load_and_process_tweets` in `tweet_preprocessor.py`
```python
processed_tweets = [
    "[Author: Trader_XO] @MaxController Got cut at $5 \n\nBought back in at $1 and sold again at 1.90",
    "[Author: Trader_XO] @TraderMagus Grifters are efficient that much I can tell you for free \n\nParticularly the ones who have found their balls again after a 15k move up off the lows"
]
```

3. In `load_documents` after combining tweets (`combined_text`)
```python
combined_text = """[Author: Trader_XO] @MaxController Got cut at $5 \n\nBought back in at $1 and sold again at 1.90
[Author: Trader_XO] @TraderMagus Grifters are efficient that much I can tell you for free \n\nParticularly the ones who have found their balls again after a 15k move up off the lows"""
```

4. After text splitting in `load_documents` (`doc_splits`)
```python
doc_splits = [
    "[Author: Trader_XO] @MaxController Got cut at $5 \n\nBought back in at $1 and sold again at 1.90",
    "[Author: Trader_XO] @TraderMagus Grifters are efficient that much I can tell you for free \n\nParticularly the ones who have found their balls again after a 15k move up off the lows"
]
```
Note: The actual splits might be different depending on the `chunk_size` and the length of the tweets.

5. In `create_vectorstore_and_retriever`, after converting to Document objects
```python
documents = [
    Document(page_content="[Author: Trader_XO] @MaxController Got cut at $5 \n\nBought back in at $1 and sold again at 1.90"),
    Document(page_content="[Author: Trader_XO] @TraderMagus Grifters are efficient that much I can tell you for free \n\nParticularly the ones who have found their balls again after a 15k move up off the lows")
]
```

6. After creating the vectorstore (not directly visible, but conceptually)
The vectorstore will contain vector representations of each document. For example:
```python
vector_representations = [
    [0.1, 0.2, 0.3, ..., 0.9],  # Vector for first document
    [0.2, 0.4, 0.1, ..., 0.7]   # Vector for second document
]
```

7. Final retriever object
The retriever is a function that, when given a query, will return the most relevant documents. For example:
```python
query = "What happened with the $5 trade?"
relevant_docs = retriever.get_relevant_documents(query)
# Might return:
# [Document(page_content="[Author: Trader_XO] @MaxController Got cut at $5 \n\nBought back in at $1 and sold again at 1.90")]
```


--- File: ./src/agent/graph/graph_state.py ---
from typing import List, TypedDict
import logging

class GraphState(TypedDict):
    question: str
    generation: str
    search: str
    data: List[str]
    steps: List[str]

def retrieve(state):
    from src.agent.rag_agent import retriever  # Move import here
    logging.info(f"Retrieving data for question: {state['question']}")
    question = state["question"]
    data = retriever.invoke(question)
    steps = state["steps"]
    steps.append("retrieve_data")
    logging.info(f"Data retrieved for question: {question}")
    return {"data": data, "question": question, "steps": steps}

def generate(state):
    from src.agent.rag_agent import rag_chain  # Move import here
    logging.info(f"Generating answer for question: {state['question']}")
    question = state["question"]
    data = state["data"]
    generation = rag_chain.invoke({"data": data, "question": question})
    steps = state["steps"]
    steps.append("generate_answer")
    logging.info(f"Answer generated for question: {question}")
    return {
        "data": data,
        "question": question,
        "generation": generation,
        "steps": steps,
    }

def web_search(state):
    from src.agent.rag_agent import web_search_tool  # Move import here
    logging.info(f"Performing web search for question: {state['question']}")
    question = state["question"]
    data = state.get("data", [])
    steps = state["steps"]
    steps.append("web_search")
    web_results = web_search_tool.invoke({"query": question})
    data.extend(web_results)
    logging.info(f"Web search completed for question: {question}")
    return {"data": data, "question": question, "steps": steps}

def decide_to_generate(state):
    logging.info("Deciding whether to generate or search...")
    data = state.get("data", [])
    if not data:
        logging.info("No data found, deciding to search.")
        return "search"
    else:
        logging.info("Data found, deciding to generate.")
        return "generate"

--- File: ./src/agent/graph/graph_workflow.py ---
import logging
from langgraph.graph import StateGraph
from src.agent.graph.graph_state import GraphState, retrieve, generate, web_search, decide_to_generate

def setup_workflow():
    logging.info("Setting up the workflow graph...")
    workflow = StateGraph(GraphState)
    workflow.add_node("retrieve", retrieve)
    workflow.add_node("generate", generate)
    workflow.add_node("web_search", web_search)

    workflow.set_entry_point("retrieve")
    workflow.add_conditional_edges(
        "retrieve",
        decide_to_generate,
        {
            "search": "web_search",
            "generate": "generate",
        },
    )
    workflow.add_edge("web_search", "generate")

    graph = workflow.compile()
    return graph

--- File: ./src/agent/__init__.py ---
# src/agent/__init__.py

from .rag_agent import get_rag_response  # Ensure correct import



--- File: ./src/agent/rag/rag_chain_setup.py ---
# src/agent/rag/rag_chain_setup.py

from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

def setup_rag_chain():
    prompt = PromptTemplate(
        template="""
You are an AI assistant specialized in creating engaging, "degen style" tweets that are both educational and informative. Your task is to craft tweets based on NEAR Protocol's Twitter posts and content from NEARMobile partners. Ensure that the tweets resonate with the crypto community, incorporating trending slang and a lively tone while conveying valuable information.

Conversation History:
{history}

Guidelines:

- Analyze the provided NEAR Protocol Twitter posts and NEARMobile partner content.
- Create tweets that blend an educational and informative content.
- Highlight key updates, features, partnerships, and other relevant information from NEAR Protocol and NEARMobile.
- Avoid repetitive phrases and strive for creativity in expression.
- Ensure factual accuracy based on the provided data.

Current Task:
{question}

Data from NEAR Protocol and NEARMobile:
{data}

Tweet:
""",
        input_variables=["history", "question", "data"],
    )

    llm = ChatOpenAI(model="gpt-4o", temperature=0.7, max_tokens=500)
    rag_chain = prompt | llm | StrOutputParser()
    return rag_chain


--- File: ./src/agent/utils.py ---
import re
import unicodedata
from src.agent.data.account_mappings import ACCOUNT_MAPPINGS

def normalize_text(text):
    # Remove accents and convert to lowercase
    text = ''.join(
        c for c in unicodedata.normalize('NFD', text)
        if unicodedata.category(c) != 'Mn'
    )
    return text.lower()

def extract_accounts(question, history=""):
    question_normalized = normalize_text(question)
    history_normalized = normalize_text(history)
    combined_text = question_normalized + " " + history_normalized
    mentioned_accounts = set()

    for folder_name, name_variations in ACCOUNT_MAPPINGS.items():
        for name in name_variations:
            name_normalized = normalize_text(name)
            # Use word boundaries to avoid partial matches
            pattern = r'\b' + re.escape(name_normalized) + r'\b'
            if re.search(pattern, combined_text):
                mentioned_accounts.add(folder_name)
                break  # Stop checking other variations for this account

    return list(mentioned_accounts)


--- File: ./src/agent/rag_agent.py ---
import logging
from src.agent.data.data_management import load_and_prepare_data
from src.agent.rag.rag_chain_setup import setup_rag_chain
from src.agent.utils import extract_accounts
from src.agent.search_tools.search_tools import get_web_search_tool

def get_rag_response(question: str, history=""):
    logging.info(f"Generating response for question: {question}")

    # Extract relevant accounts from the user's question
    accounts_to_load = extract_accounts(question, history)
    logging.info(f"Accounts extracted: {accounts_to_load}")

    if not accounts_to_load:
        logging.warning("No relevant accounts found. Using default accounts.")
        accounts_to_load = ['NEARMobile_app']  # Use a default account if none found

    # Load data and create retriever dynamically
    retriever = load_and_prepare_data(accounts_to_load)

    # If no retriever could be created (no data loaded), consider handling it
    if retriever is None:
        return "Sorry, I couldn't find any relevant information to generate a tweet.", []

    # Set up RAG chain
    rag_chain = setup_rag_chain()

    # Retrieve documents
    logging.info(f"Retrieving data for question: {question}")
    docs = retriever.invoke(question)

    # If no documents found, perform web search
    if not docs:
        logging.info("No relevant documents found in vectorstore, performing web search.")
        web_search_tool = get_web_search_tool()
        web_results = web_search_tool.run(question)
        data_texts = web_results
    else:
        # Prepare data texts from retrieved documents
        data_texts = "\n".join([doc.page_content for doc in docs])

        # Log the data being passed to the prompt
    logging.info(f"Data passed to the prompt:\n{data_texts}")

    # Generate response using RAG chain
    response = rag_chain.invoke({"question": question, "data": data_texts, "history": history})

    return response, []


--- File: ./src/agent/agent.py ---
import os
import json
import logging
from typing import List, Optional
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# Configure logging
#logging.basicConfig(level=logging.INFO)

# Define the state
class GraphState(BaseModel):
    messages: List[dict] = Field(default_factory=list)
    prompt: str = ""
    retrieved_docs: List[Document] = Field(default_factory=list)
    generation: str = ""
    steps: List[str] = Field(default_factory=list)
    iterations: int = 0

    """Represents the state of the graph.

    Attributes:
        doc (Document): The document associated with the state.
    """
    doc: Optional[Document] = None

    class Config:
        """Pydantic configuration for the GraphState model."""
        arbitrary_types_allowed = True

# Agent class for retrieval
class RetrieveAgent:
    def __init__(self, retriever):
        self.retriever = retriever

    def __call__(self, state: GraphState):
        logging.info("Retrieving relevant documents...")
        question = state.prompt
        retrieved_docs = self.retriever.invoke(question)
        state.retrieved_docs = retrieved_docs
        state.steps.append("retrieved_docs")
        return state

# Agent class for generating response
class GenerateAgent:
    def __init__(self, env):
        self.env = env
        self.prompt_template = self.create_prompt_template()

    def create_prompt_template(self):
        """Sets up the prompt template for generating responses."""
        prompt = PromptTemplate(
            template="""You are an AI assistant specialized in creating engaging, "degen style" tweets that are both educational and informative. Your task is to craft tweets based on NEAR Protocol's Twitter posts and content from NEARMobile partners. Ensure that the tweets resonate with the crypto community, incorporating trending slang and a lively tone while conveying valuable information.

            
Current history: {history}

Users question: {question}
Guidelines:
1. Analyze the provided NEAR Protocol Twitter posts and NEARMobile partner content.
2. Create long tweets that blend a "degen" (degenerate) style‚Äîcharacterized by high energy, enthusiasm, and crypto slang‚Äîwith educational and informative content.
3. Highlight key updates, features, partnerships, and other relevant information from NEAR Protocol and NEARMobile.
4. Use hashtags appropriately to increase visibility within the crypto community.
6. Avoid repetitive phrases and strive for creativity in expression.
7. Ensure factual accuracy based on the provided data.
8. Twits must be long and inlcude detailed info.


Data:
{data}

Tweet/Tweets:
""",
            input_variables=["question", "data", "history"],
        )
        return prompt

    def __call__(self, state: GraphState):
        """Generates a response based on the current state."""
        logging.info("Generating response...")
        question = state.prompt
        data_texts = "\n".join([doc.page_content for doc in state.retrieved_docs])

        # Prepare the prompt using the template
        prompt = self.prompt_template.format(data=data_texts)

        # Get the conversation history
        messages = self.env.list_messages()

        # Add the detailed prompt as a system message
        messages.append({"role": "system", "content": prompt})

        # Add the user's question as a user message
        messages.append({"role": "user", "content": question})

        # Call the language model
        response = self.env.completion(messages)
        state.generation = response
        state.steps.append("generated_answer")
        return state

def load_documents(file_path):
    """Load documents from a JSON file."""
    try:
        with open(file_path, 'r') as file:
            tweet_data = json.load(file)
        docs = []
        for tweet_entry in tweet_data:
            if tweet_entry.get('Error') is None and 'Tweet' in tweet_entry:
                tweet = tweet_entry['Tweet']
                tweet_text = f"[Author: {tweet['Username']}] {tweet['Text']}"
                docs.append(Document(page_content=tweet_text))
        # Split documents
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=0)
        split_docs = []
        for doc in docs:
            splits = text_splitter.split_text(doc.page_content)
            for split in splits:
                split_docs.append(Document(page_content=split))
        return split_docs
    except Exception as e:
        logging.error(f"Error loading tweets: {e}")
        return []

def create_vectorstore_and_retriever(documents):
    """
    Create vector store and retriever.

    :param documents: The list of documents.
    :type documents: List[Document]
    :return: The retriever object.
    :rtype: Retrieval
    """
    # Define tokenizer arguments to avoid the warning
    tokenizer_kwargs = {
        'clean_up_tokenization_spaces': True
    }

    # Initialize embeddings with tokenizer arguments
    embeddings = HuggingFaceEmbeddings(
        model_name="all-MiniLM-L6-v2",
        model_kwargs={
            'tokenizer_kwargs': tokenizer_kwargs
        }
    )
    vectorstore = FAISS.from_documents(documents, embeddings)
    retriever = vectorstore.as_retriever(k=4)
    return retriever


# Define the main function
def main(env):
    """Main function to run the agent."""
    # Initialize the agent only once
    if not hasattr(main, "agent_initialized"):
        main.agent_initialized = True
        # Load and prepare data
        data_path = "data/twitter_data/memecoin_tweets.json"
        documents = load_documents(data_path)
        retriever = create_vectorstore_and_retriever(documents)
        # Assign agents
        main.retrieve_agent = RetrieveAgent(retriever)
        main.generate_agent = GenerateAgent(env)
        # Compile the graph
        graph_builder = StateGraph(GraphState)
        graph_builder.add_node("retrieve", main.retrieve_agent)
        graph_builder.add_node("generate", main.generate_agent)
        graph_builder.add_edge(START, "retrieve")
        graph_builder.add_edge("retrieve", "generate")
        graph_builder.add_edge("generate", END)
        main.graph = graph_builder.compile()

    messages = env.list_messages()
    next_actor = env.get_next_actor()

    if not messages:
        # No previous messages, initialize conversation
        env.set_next_actor("user")
        env.request_user_input()
        return

    if next_actor == "user":
        # After the user inputs a message, set next_actor to 'agent'
        env.set_next_actor("agent")
    elif next_actor == "agent":
        last_message = messages[-1]
        if last_message['role'] == 'user':
            question = last_message['content']
            initial_state = GraphState(prompt=question)
            # Invoke the graph and get the result
            result = main.graph.invoke(initial_state)
            agent_response = result['generation']
            # Add the agent's response to the environment
            env.add_message("agent", agent_response)
            env.set_next_actor("user")
    else:
        # Default behavior: request user input
        env.set_next_actor("user")
        env.request_user_input()
        return

    # Request user input if it's the user's turn
    if env.get_next_actor() == "user":
        env.request_user_input()


# Entry point for the agent
if __name__ == "__main__":
    main(env)

--- File: ./src/agent/evaluation/evaluation.py ---
from langchain import hub
from langchain_openai import ChatOpenAI

grade_prompt_answer_accuracy = hub.pull("langchain-ai/rag-answer-vs-reference")

def answer_evaluator(run, example) -> dict:
    """
    A simple evaluator for RAG answer accuracy
    """
    input_question = example.inputs["input"]
    reference = example.outputs["output"]
    prediction = run.outputs["response"]

    llm = ChatOpenAI(model="gpt-4", temperature=0)
    answer_grader = grade_prompt_answer_accuracy | llm

    score = answer_grader.invoke(
        {
            "question": input_question,
            "correct_answer": reference,
            "student_answer": prediction,
        }
    )
    score = score["Score"]
    return {"key": "answer_v_reference_score", "score": score}

def check_trajectory_custom(root_run, example) -> dict:
    """
    Check if all expected tools are called in exact order and without any additional tool calls.
    """
    expected_trajectory_1 = [
        "retrieve_data",
        "grade_data_retrieval",
        "web_search",
        "generate_answer",
    ]
    expected_trajectory_2 = [
        "retrieve_data",
        "grade_data_retrieval",
        "generate_answer",
    ]

    tool_calls = root_run.outputs["steps"]
    print(f"Tool calls custom agent: {tool_calls}")
    if tool_calls == expected_trajectory_1 or tool_calls == expected_trajectory_2:
        score = 1
    else:
        score = 0

    return {"score": int(score), "key": "tool_calls_in_exact_order"}

--- File: ./src/agent/data/vector_store.py ---
# src/agent/data/vector_store.py

from langchain_community.vectorstores import SKLearnVectorStore
from langchain_openai import OpenAIEmbeddings

def create_vectorstore_and_retriever(documents):
    # No need to convert documents if they are already Document objects
    vectorstore = SKLearnVectorStore.from_documents(
        documents=documents,
        embedding=OpenAIEmbeddings(),
    )
    retriever = vectorstore.as_retriever(search_kwargs={'k': 30})
    return retriever

--- File: ./src/agent/data/account_mappings.py ---
ACCOUNT_MAPPINGS = {
    'NEARMobile_app': [
        'nearmobile.app', 'nearmobile', 'mobile app', 'wallet', 'nearwallet',
        'noncustodial', 'selfcustodial', 'peersyst', 'mobile', 'crypto wallet',
        'blockchain', 'NEAR', 'decentralized', 'self-custody', 'app'
    ],
    'NEARMintern': [
        'intern', 'NEARMobile', 'dapps', 'developer', 'blockchain',
        'learning', 'mobile development', 'NEAR', 'apprenticeship'
    ],
    'nearblocks': [
        'explorer', 'blocks', 'onchain', 'data', 'nearblock', 'txhash',
        'transactions', 'blockchain explorer', 'analytics', 'NEAR',
        'blockchain data', 'monitoring', 'block explorer'
    ],
    'NEARProtocol': [
        'nearprotocol', 'near', 'nearfoundation', 'illia', 'news',
        'blockchain', 'protocol', 'foundation', 'updates',
        'crypto', 'technology', 'development', 'community'
    ],
    'finance_ref': [
        'ref', 'reffinance', 'dapp', 'swap', 'pools', 'liquiditypools',
        'trade', 'amm', 'usdc', 'usdt', 'frax', 'top', 'tvl', 'finance',
        'DEX', 'liquidity', 'DeFi', 'trading', 'NEAR', 'REF Finance',
        'automated market maker', 'cryptocurrency'
    ],
    'ref_intern': [
        'ref', 'intern', 'dapp', 'swap', 'pools', 'liquiditypools',
        'trade', 'amm', 'usdc', 'usdt', 'frax', 'top', 'tvl', 'internship',
        'developer', 'learning', 'DeFi', 'NEAR', 'REF Finance',
        'cryptocurrency', 'AMM'
    ],
    'meta_pool': [
        'pool', 'pools', 'stake', 'stNEAR', 'mpDAO', 'dao', 'reStake',
        'liquid', 'tvl', 'dapp', 'Meta Pool', 'staking', 'liquid staking',
        'NEAR', 'DeFi', 'liquidity', 'staking pool', 'cryptocurrency'
    ],
    'burrow_finance': [
        'lending', 'lend', 'borrow', 'burrow', 'usdc', 'usdt', 'frax',
        'stake', 'pools', 'tvl', 'dapp', 'Burrow Finance', 'DeFi', 'NEAR',
        'crypto lending', 'liquidity', 'borrowing', 'loans', 'stablecoins',
        'finance'
    ],
    'beepopula': [
        'community', 'dapp', 'privacy', 'onchain', 'social', 'BeePopula',
        'social media', 'blockchain', 'NEAR', 'decentralized app',
        'community platform', 'on-chain social'
    ],
    'DeltaBotTeam': [
        'dca', 'trade', 'gachapon', 'airdrop', 'swing', 'bots', 'ai',
        'stablecoin', 'usdc', 'usdt', 'aibot', 'tradebot', 'tokens',
        'auto', 'dapp', 'Delta Bot Team', 'automated trading', 'NEAR',
        'cryptocurrency', 'trading signals', 'deltatrade'
    ],
    'shitzuonnear': [
        'dogshit', 'shitzu', 'meme', 'stake', 'validator', 'dev', 'build',
        'NEAR', 'memecoin', 'blockchain', 'cryptocurrency', 'developer',
        'staking', 'community'
    ],
    'memedotcooking': [
        'meme', 'memecoin', 'launchpad', 'buy', 'sell', 'rug',
        'meme.cooking', 'cook', 'memecooking', 'shitzu', 'dogshit', 'NEAR',
        'cryptocurrency', 'token', 'trading', 'blockchain', 'cooking'
    ],
    'sharddog': [
        'nft', 'nfts', 'mint', 'sharddog', 'community', 'build',
        'blockchain', 'NEAR', 'collectibles', 'digital art', 'crypto',
        'non-fungible tokens'
    ],
    'nadabots': [
        'certificate', 'did', 'proof', 'humanproof', 'id', 'bots', 'nada',
        'identity', 'verification', 'blockchain', 'decentralized identity',
        'NEAR', 'authentication'
    ],
    'potlock_': [
        'funding', 'ai', 'design', 'potlock', 'pot', 'startup',
        'artificial intelligence', 'investment', 'entrepreneurship',
        'innovation', 'technology', 'development', 'AGI'
    ],
    'JumpDeFi': [
        'jump', 'defi', 'stake', 'nft', 'DeFi', 'staking', 'NFT',
        'crypto', 'blockchain', 'NEAR', 'finance', 'cryptocurrency',
        'investment'
    ],
    'TokenBridgeApp': [
        'bridge', 'swap', 'transfer', 'crosschain', 'solana', 'binance',
        'arbitrum', 'token', 'blockchain', 'NEAR', 'cryptocurrency',
        'exchange', 'interoperability', 'multi-chain', 'token bridge'
    ],
    'tknhomes': [
        'token', 'marketplace', 'launchpad', 'meme', 'memecoin', 'NEAR',
        'cryptocurrency', 'blockchain', 'trading', 'tokens', 'home',
        'real estate', 'investment'
    ],
    'NEARDevHub': [
        'dev', 'build', 'ai', 'chain', 'onnear', 'devrel', 'tutorial',
        'NEAR', 'developer', 'development', 'blockchain', 'learning',
        'resources', 'community', 'education', 'development hub'
    ],
    'NEARdevs': [
        'dev', 'build', 'ai', 'chain', 'onnear', 'NEAR', 'developers',
        'development', 'blockchain', 'artificial intelligence',
        'community', 'technology', 'coding'
    ],
    'ilblackdragon': [
        'founder', 'illia', 'dev', 'build', 'nearceo', 'boss',
        'blackdragon', 'nearprotocol', 'nearfoundation', 'NEAR',
        'blockchain', 'CEO', 'developer', 'entrepreneur', 'technology',
        'leadership', 'innovation'
    ],
    'GNearAi': [
        'meme', 'ai', 'NEAR', 'artificial intelligence', 'memes', 'crypto',
        'blockchain', 'technology', 'machine learning', 'innovation'
    ],
    'vxyz_near': [
        'community', 'NEAR', 'blockchain', 'network', 'crypto',
        'engagement', 'collaboration'
    ],
    'NEARQuant': [
        'community', 'news', 'alpha', 'NEAR', 'blockchain',
        'quantitative analysis', 'trading', 'crypto', 'insights',
        'market analysis', 'data'
    ],
    'taostats': [
        'ai', 'bittensor', 'masaAI', 'web3', 'blockchain', 'statistics',
        'data', 'analysis', 'artificial intelligence', 'cryptocurrency',
        'machine learning', 'neural networks'
    ],
    'nearcatalog': [
        'community', 'dapps', 'dappradar', 'projects', 'news', 'trends',
        'NEAR', 'catalog', 'applications', 'blockchain', 'directory',
        'crypto', 'project listing', 'ecosystem'
    ],
    'marior_dev': [
        'community', 'dev', 'shitzu', 'orderly', 'futures', 'derivatives',
        'developer', 'NEAR', 'blockchain', 'trading', 'crypto', 'memecoin',
        'financial instruments', 'programming'
    ],
    'SKYTONET_': [
        'community', 'mod', 'ambassador', 'ref', 'shitzu', 'meme',
        'memedotcooking', 'NEAR', 'moderator', 'ambassador', 'blockchain',
        'crypto', 'memecoin', 'cooking', 'engagement'
    ],
    'invokerlabs': [
        'dev', 'build', 'nearblocks', 'NEAR', 'developer', 'blockchain',
        'technology', 'innovation', 'laboratory', 'software development',
        'solutions'
    ],
    'Nearsend_io': [
        'dev', 'nep', 'send', 'invokerlabs', 'bulk', 'transactions',
        'NEAR', 'developer', 'blockchain', 'sending', 'crypto',
        'transactions', 'NEP standards', 'messaging'
    ],
    'questflow': [
        'project', 'dapp', 'ai', 'agents', 'NEAR', 'blockchain',
        'artificial intelligence', 'decentralized app', 'automation',
        'workflow', 'task management', 'productivity'
    ],
    'DayTrader888': [
        'growth', 'veax', 'dex', 'degen', 'day trading', 'NEAR',
        'blockchain', 'crypto', 'decentralized exchange', 'finance',
        'cryptocurrency', 'trading strategies'
    ],
    'NearKatToken': [
        'meme', 'memecoin', 'token', 'kat', 'cat', 'NEAR',
        'cryptocurrency', 'blockchain', 'token', 'memecoin',
        'cat-themed', 'crypto asset', 'community token'
    ],
    'ai_pgf': [
        'potlock', 'ai', 'funding', 'agi', 'artificial intelligence',
        'investment', 'NEAR', 'blockchain', 'AGI (Artificial General Intelligence)',
        'technology', 'startup funding'
    ],
    'hotdao_': [
        'hot', 'herewallet', 'dao', 'telegram', 'NEAR', 'community',
        'decentralized autonomous organization', 'blockchain', 'wallet',
        'communication', 'messaging'
    ],
    'p_volnov': [
        'hotdao', 'herewallet', 'founder', 'dev', 'NEAR', 'developer',
        'blockchain', 'entrepreneur', 'technology', 'leadership',
        'wallet development'
    ],
    'ThunderHoodlab': [
        'meme', 'dex', 'marketplace', 'launchpad', 'trade', 'deploy',
        'NEAR', 'blockchain', 'cryptocurrency', 'decentralized exchange',
        'trading', 'development', 'cryptocurrency exchange'
    ],
    'getmasafi': [
        'ai', 'agents', 'scrape', 'data', 'twitterscrape', 'discord',
        'telegram', 'web', 'webscrape', 'mine', 'bittensor', 'tao',
        'blockchain', 'data mining', 'artificial intelligence',
        'social media', 'automation'
    ],
    'growthmate_xyz': [
        'data', 'onchain', 'dapps', 'trends', 'community', 'NEAR',
        'blockchain', 'analytics', 'growth', 'crypto', 'market trends',
        'user engagement'
    ],
    'NearGamesDAO': [
        'community', 'game', 'gamers', 'dao', 'play', 'NEAR',
        'blockchain', 'gaming', 'decentralized autonomous organization',
        'crypto', 'entertainment', 'interactive'
    ],
    'SailGPESP': [
        'sailgp', 'nearspain', 'nearesp', 'nearpartners', 'nearsports',
        'NEAR', 'blockchain', 'sailing', 'sports', 'Spain',
        'partnerships', 'events'
    ],
    'elm_money': [
        'founder', 'ai', 'community', 'neardc', 'digital', 'marketing',
        'dao', 'aurora', 'apps', 'games', 'NEAR', 'blockchain',
        'entrepreneur', 'technology', 'digital marketing', 'development'
    ],
    'KagemniKarimu': [
        'dev', 'devrel', 'lava', 'magma', 'lavanet', 'rpc', 'data',
        'apps', 'host', 'storage', 'NEAR', 'blockchain', 'developer',
        'infrastructure', 'remote procedure call', 'software'
    ],
    'xgilxgil': [
        'dev', 'lava', 'lavanet', 'rpc', 'magma', 'NEAR', 'blockchain',
        'developer', 'infrastructure', 'technology', 'networking'
    ],
    'magmadevs': [
        'dev', 'lava', 'lavanet', 'magma', 'NEAR', 'blockchain',
        'developer', 'infrastructure', 'software development',
        'technology', 'network solutions'
    ],
    'consensus128': [
        'marketing', 'community', 'lava', 'rpc', 'NEAR', 'blockchain',
        'infrastructure', 'communication', 'promotion', 'networking',
        'technology'
    ],
    'theinterestedr1': [
        'founder', 'cto', 'lava', 'dev', 'build', 'NEAR', 'blockchain',
        'developer', 'technology', 'leadership', 'innovation',
        'infrastructure'
    ],
    'NimrodxLava': [
        'dev', 'lava', 'r&d', 'magma', 'NEAR', 'blockchain',
        'research and development', 'developer', 'technology',
        'innovation', 'infrastructure'
    ],
    'beanonnear': [
        'meme', 'memecoin', 'token', 'mrbean', 'stake', 'nft', 'ref',
        'jump', 'NEAR', 'blockchain', 'cryptocurrency', 'staking',
        'non-fungible tokens', 'DEX', 'finance', 'comedy'
    ],
    'fraxfinance': [
        'stable', 'coin', 'token', 'lend', 'borrow', 'defi', 'fiat',
        'stake', 'sfrax', 'NEAR', 'blockchain', 'cryptocurrency',
        'stablecoin', 'finance', 'lending', 'borrowing', 'DeFi'
    ],
    'OpenForest_': [
        'rwa', 'onchain', 'carbon', 'consensuslayer', 'layer', 'defi',
        'stake', 'lending', 'bonds', 'token', 'OpenForest', 'real-world assets',
        'carbon credits', 'DeFi', 'staking', 'tokenization', 'environmental',
        'sustainability', 'blockchain', 'NEAR', 'green finance', 'ESG',
        'climate change', 'sustainable finance'
    ],
    'edgevideoai': [
        'stream', 'space', 'video', 'fast', 'revenue', 'edge', 'ai',
        'EdgeVideo AI', 'streaming', 'edge computing', 'artificial intelligence',
        'blockchain', 'NEAR', 'monetization', 'video streaming', 'technology',
        'content delivery', 'media'
    ],
    'pironidi': [
        'didier', 'defi', 'dev', 'growth', 'founder', 'pikespeak',
        'ref', 'reffinance', 'Didier', 'DeFi', 'developer', 'growth',
        'founder', 'Pikes Peak', 'REF Finance', 'NEAR', 'blockchain',
        'entrepreneurship', 'finance', 'cryptocurrency', 'innovation',
        'DEX', 'decentralized exchange'
    ],
    'NEARChainStatus': [
        'onchain', 'data', 'validator', 'infra', 'community', 'news',
        'devrel', 'updates', 'status', 'NEAR Chain Status', 'on-chain data',
        'infrastructure', 'blockchain', 'NEAR', 'network status',
        'node monitoring', 'development updates', 'network health',
        'system status'
    ],
    'marrowng': [
        'metapool', 'marketing', 'founder', 'community', 'latam', 'espa√±ol',
        'Marrow NG', 'blockchain', 'NEAR', 'Latin America', 'Spanish',
        'staking', 'liquid staking', 'entrepreneurship', 'growth',
        'communication'
    ],
    'noahmajor1776': [
        'nono', 'nearmaxi', 'content', 'creator', 'community', 'news',
        'dev', 'Noah Major', 'NEAR Maxi', 'blockchain', 'NEAR',
        'developer', 'crypto enthusiast', 'social media', 'content creation'
    ],
    'NEAR_Arabic': [
        'nation', 'arab', 'language', 'community', 'NEAR Arabic',
        'blockchain', 'NEAR', 'Arabic language', 'Middle East',
        'community events', 'updates', 'localization', 'education'
    ],
    'EsNearEs': [
        'espa√±ol', 'latam', 'noticias', 'news', 'community', 'EsNearEs',
        'Spanish', 'blockchain', 'NEAR', 'Latin America', 'community',
        'events', 'updates', 'crypto news'
    ],
    'NearPositive': [
        'community', 'news', 'NEAR Positive', 'blockchain', 'NEAR',
        'updates', 'crypto news', 'engagement', 'information', 'positive news'
    ],
    'Near_Colombia': [
        'latam', 'nation', 'espa√±ol', 'colombia', 'news', 'community',
        'NEAR Colombia', 'blockchain', 'NEAR', 'Latin America', 'Spanish',
        'community events', 'updates', 'Colombia'
    ],
    'MITTE_gg': [
        'nft', 'dapp', 'nftmarketplace', 'trade', 'trading', 'MITTE',
        'blockchain', 'NEAR', 'NFTs', 'marketplace', 'decentralized app',
        'buy', 'sell', 'collectibles', 'crypto art'
    ],
    'EvgenSkydan': [
        'ukraine', 'ucrania', 'nearua', 'nearuaguild', 'neardc', 'explorer',
        'news', 'dev', 'onchain', 'community', 'Evgen Skydan', 'blockchain',
        'NEAR', 'developer', 'Ukraine', 'community member', 'on-chain data',
        'NEAR UA Guild'
    ],
    'jjyuannear': [
        'jerry', 'yuannear', 'nearusa', 'usa', 'banyan', 'founder', 'news',
        'dev', 'devrel', 'community', 'Jerry Yuan', 'blockchain', 'NEAR',
        'developer', 'entrepreneur', 'USA', 'community events', 'developer relations'
    ],
    'Banyan_NEAR': [
        'build', 'dev', 'project', 'banyan', 'nearprotocol', 'develop',
        'Banyan NEAR', 'blockchain', 'NEAR', 'development', 'projects',
        'technology', 'innovation', 'software'
    ],
    'SourceDegen': [
        'degen', 'community', 'Source Degen', 'blockchain', 'NEAR',
        'crypto enthusiast', 'community engagement', 'trading', 'DeFi',
        'cryptocurrency'
    ],
    'rendal73': [
        'degen', 'community', 'Rendal', 'blockchain', 'NEAR', 'crypto enthusiast',
        'community member', 'trading', 'cryptocurrency', 'engagement'
    ],
    'n0trdame': [
        'degen', 'community', 'Notrdame', 'blockchain', 'NEAR',
        'crypto enthusiast', 'community member', 'trading', 'cryptocurrency'
    ],
    'here_wallet': [
        'wallet', 'competition', 'hot', 'telegram', 'Here Wallet',
        'blockchain', 'NEAR', 'cryptocurrency', 'security', 'user-friendly',
        'crypto wallet', 'technology', 'communication'
    ],
    'cosmos': [
        'cosmos', 'cosmossdk', 'ibc', 'consensuslayer', 'layer', 'atom',
        'Cosmos', 'blockchain', 'Cosmos SDK', 'IBC', 'Inter-Blockchain Communication',
        'consensus layer', 'ATOM', 'network', 'cryptocurrency', 'ecosystem'
    ],
    'axelar': [
        'bridge', 'axelar', 'token', 'Axelar', 'blockchain', 'cross-chain',
        'interoperability', 'token bridge', 'cryptocurrency', 'network',
        'security', 'decentralized'
    ],
    'EvmosOrg': [
        'evm', 'network', 'evmos', 'Evmos', 'blockchain', 'EVM compatible',
        'network', 'Cosmos', 'Ethereum Virtual Machine', 'interoperability',
        'cryptocurrency', 'development'
    ],
    'osmosiszone': [
        'osmosis', 'cosmos', 'atom', 'Osmosis', 'blockchain',
        'Cosmos', 'ATOM', 'decentralized exchange', 'DEX', 'liquidity',
        'staking', 'cryptocurrency', 'trading'
    ],
    'near_malaysia': [
        'nation', 'community', 'malaysia', 'malasia', 'asia', 'NEAR Malaysia',
        'blockchain', 'NEAR', 'community events', 'updates', 'localization',
        'development', 'Southeast Asia'
    ],
    'ekosubagyo': [
        'maxone', 'metapool', 'community', 'ambassador', 'Eko Subagyo',
        'blockchain', 'NEAR', 'Meta Pool', 'community engagement',
        'ambassador', 'staking', 'liquid staking', 'crypto enthusiast'
    ],
    'alannetwork_': [
        'metapool', 'latam', 'openweb', 'dev', 'Alan Network',
        'blockchain', 'NEAR', 'Meta Pool', 'Latin America', 'developer',
        'open web', 'technology', 'innovation'
    ],
    'swisshustler': [
        'nearprotocol', 'swiss', 'nearfoundation', 'Swiss Hustler',
        'blockchain', 'NEAR', 'Switzerland', 'entrepreneur', 'technology',
        'development', 'community', 'innovation'
    ],
    'Mikikin8': [
        'defi', 'founder', 'dev', 'defishards', 'shards',
        'Mikikin', 'blockchain', 'NEAR', 'DeFi', 'developer', 'founder',
        'sharding', 'finance', 'innovation'
    ],
    'DeFiShardsxyz': [
        'defi', 'sharding', 'shards', 'defishards', 'nft', 'docs',
        'liquid', 'stake', 'DeFi Shards', 'blockchain', 'NEAR', 'DeFi',
        'sharding', 'NFTs', 'documentation', 'liquid staking', 'finance'
    ],
    'mraltantutar': [
        'nearprotocol', 'nearfoundation', 'georgia', 'founder', 'dev',
        'chain', 'chainabstracted', 'signatures', 'Mr. Altantutar', 'blockchain',
        'NEAR', 'developer', 'founder', 'chain abstraction', 'cryptography',
        'signatures', 'Georgia (country)'
    ],
    'aescobarindo': [
        'escobar', 'reffinance', 'ref', 'dapdap', 'dex', 'dev', 'marketing',
        'community', 'founder', 'playember', 'A. Escobar', 'blockchain',
        'NEAR', 'developer', 'marketing', 'community engagement',
        'decentralized exchange', 'gaming'
    ],
    'chronear': [
        'dev', 'build', 'chain', 'chainabstraction', 'abstraction',
        'signatures', 'chainsig', 'Chron NEAR', 'blockchain', 'NEAR',
        'developer', 'chain abstraction', 'cryptography', 'innovation',
        'technology'
    ],
    'NearIndia': [
        'india', 'asia', 'nation', 'community', 'dev', 'news', 'NEAR India',
        'blockchain', 'NEAR', 'developer', 'community events', 'updates',
        'localization', 'technology', 'South Asia'
    ],
    'yuvalxyz': [
        'magma', 'lava', 'lavanet', 'marketing', 'bd', 'community', 'infra',
        'data', 'Yuval', 'blockchain', 'NEAR', 'marketing', 'business development',
        'community engagement', 'infrastructure', 'data services'
    ],
    'yaircleper': [
        'founder', 'lava', 'lavanet', 'magma', 'cleper', 'Yair Cleper',
        'blockchain', 'NEAR', 'developer', 'founder', 'infrastructure',
        'technology', 'innovation', 'Lava Network'
    ],
    'thelittlesnft': [
        'nft', 'thelittles', 'nfts', 'design', 'The Littles NFT',
        'blockchain', 'NEAR', 'NFTs', 'digital art', 'collectibles',
        'crypto art', 'design', 'creative'
    ],
    'bodega_web3': [
        'bodega', 'community', 'game', 'dev', 'collectibles', 'nft', 'nfts',
        'Bodega Web3', 'blockchain', 'NEAR', 'gaming', 'developer',
        'collectibles', 'NFTs', 'community engagement', 'web3'
    ],
    'AlexSkidanov': [
        'founder', 'nearfounder', 'nearprotocol', 'dev', 'news', 'community',
        'Alex Skidanov', 'blockchain', 'NEAR', 'developer', 'founder',
        'technology', 'innovation', 'community engagement', 'updates'
    ],
    'NearTinkerUnion': [
        'nft', 'nfts', 'collection', 'NEAR Tinker Union', 'blockchain',
        'NEAR', 'NFTs', 'digital art', 'collectibles', 'community',
        'collaboration', 'creative', 'crypto art'
    ],
    '0xshadowbrown': [
        'chain', 'chainabstractor', 'chainabstraction', 'abstraction',
        'chainsig', 'chainsignatures', 'signature', 'dev', 'build',
        'Shadow Brown', 'blockchain', 'NEAR', 'developer', 'chain abstraction',
        'cryptography', 'innovation', 'technology'
    ],
    'quadron3stat3': [
        'founder', 'news', 'nearweek', 'community', 'nearfoundation',
        'nearprotocol', 'Quadrone Estate', 'blockchain', 'NEAR', 'founder',
        'news', 'community engagement', 'NEAR Foundation', 'updates'
    ],
    'joeespano_': [
        'joe', 'sharddog', 'dev', 'devrel', 'learn', 'tutorials', 'neardevhub',
        'Joe Espano', 'blockchain', 'NEAR', 'developer', 'developer relations',
        'learning', 'tutorials', 'education', 'community'
    ],
    'Freol': [
        'dev', 'learn', 'build', 'docs', 'nearprotocol', 'neardevhub',
        'developer', 'Freol', 'blockchain', 'NEAR', 'developer',
        'learning', 'documentation', 'education', 'technology'
    ],
    'ChrisDoNEARvan': [
        'founder', 'dev', 'learn', 'devrel', 'neardevhub', 'devhub',
        'nearfoundation', 'Chris Do NEARvan', 'blockchain', 'NEAR',
        'developer', 'founder', 'developer relations', 'learning',
        'education', 'technology'
    ],
    'NearMultiverse': [
        'metapool', 'marketing', 'community', 'latam', 'ecuador',
        'NEAR Multiverse', 'blockchain', 'NEAR', 'Meta Pool',
        'marketing', 'community engagement', 'Latin America', 'Ecuador',
        'staking'
    ],
    'BrazillianCare': [
        'brazil', 'metapool', 'latam', 'growth', 'community', 'founder',
        'Brazilian Care', 'blockchain', 'NEAR', 'Brazil', 'Latin America',
        'community engagement', 'growth', 'staking', 'Meta Pool'
    ],
    'waxnear': [
        'wax', 'community', 'news', 'influencer', 'Wax NEAR',
        'blockchain', 'NEAR', 'Wax blockchain', 'community engagement',
        'news', 'influencer', 'cryptocurrency'
    ],
    'Nearbigfinance': [
        'news', 'community', 'defi', 'NEAR Big Finance', 'blockchain',
        'NEAR', 'news', 'community engagement', 'DeFi', 'finance',
        'cryptocurrency', 'updates'
    ],
    'NearVietnamHub': [
        'nation', 'news', 'vietnam', 'asia', 'community', 'NEAR Vietnam Hub',
        'blockchain', 'NEAR', 'Vietnam', 'community engagement',
        'updates', 'localization', 'Southeast Asia'
    ],
    'NearKoreaHub': [
        'nation', 'news', 'korea', 'southkorea', 'asia', 'community',
        'NEAR Korea Hub', 'blockchain', 'NEAR', 'South Korea',
        'community engagement', 'updates', 'localization', 'East Asia'
    ],
    'near_intern': [
        'intern', 'degen', 'community', 'NEAR Intern', 'blockchain',
        'NEAR', 'internship', 'crypto enthusiast', 'community engagement',
        'learning', 'development'
    ],
    'lauranear': [
        'nearprotocol', 'nearfoundation', 'product', 'Laura NEAR',
        'blockchain', 'NEAR', 'product manager', 'technology',
        'development', 'innovation', 'NEAR Foundation'
    ],
    'NameSkyApp': [
        'dapp', 'domains', 'neardomains', 'dotnear', '.near', 'accounts',
        'wallets', 'buy', 'sell', 'trade', 'NameSky', 'blockchain',
        'NEAR', 'domain names', 'decentralized app', 'marketplace',
        'crypto domains'
    ],
    'ready_layer_one': [
        'metaverse', 'build', 'community', 'nft', 'content', 'sharddog',
        'Ready Layer One', 'blockchain', 'NEAR', 'metaverse', 'development',
        'community engagement', 'NFTs', 'content creation'
    ],
    'jarednotjerry1': [
        'sharddog', 'nft', 'dev', 'community', 'build', 'Jared Not Jerry',
        'blockchain', 'NEAR', 'developer', 'community engagement',
        'NFTs', 'development', 'technology'
    ],
    'ElCafeCartel': [
        'dapp', 'game', 'nft', 'dev', 'build', 'El Cafe Cartel',
        'blockchain', 'NEAR', 'decentralized app', 'gaming',
        'NFTs', 'developer', 'community', 'technology'
    ],
    'SecretSkellies': [
        'nft', 'collection', 'art', 'nfts', 'build', 'Secret Skellies',
        'blockchain', 'NEAR', 'NFTs', 'digital art', 'collectibles',
        'crypto art', 'development', 'creative'
    ],
    'ASAC_NFT': [
        'antisocial', 'apes', 'club', 'nft', 'nfts', 'art', 'build',
        'collection', 'ASAC NFT', 'blockchain', 'NEAR', 'NFTs',
        'digital art', 'collectibles', 'crypto art', 'community'
    ],
    'AlexAuroraDev': [
        'founder', 'ceo', 'aurora', 'dev', 'Alex Aurora Dev',
        'blockchain', 'Aurora', 'NEAR', 'developer', 'founder',
        'CEO', 'technology', 'innovation', 'development'
    ],
    'near_family': [
        'family', 'news', 'community', 'nft', 'trade', 'meme',
        'NEAR Family', 'blockchain', 'NEAR', 'community engagement',
        'NFTs', 'trading', 'memes', 'crypto'
    ],
    'CalimeroNetwork': [
        'calimero', 'network', 'privacy', 'data', 'chat', 'build', 'dev',
        'asia', 'ownership', 'Calimero Network', 'blockchain', 'NEAR',
        'privacy', 'data ownership', 'development', 'technology',
        'communication', 'Asia'
    ],
    'PagodaPlatform': [
        'pagoda', 'nearprotocol', 'nearfoundation', 'infra', 'dev', 'build',
        'Pagoda Platform', 'blockchain', 'NEAR', 'infrastructure',
        'developer', 'development', 'technology', 'innovation'
    ],
    'NEARBalkan': [
        'nation', 'news', 'community', 'balkans', 'europe', 'easteurope',
        'NEAR Balkan', 'blockchain', 'NEAR', 'Balkans', 'community engagement',
        'updates', 'localization', 'Eastern Europe'
    ],
    'BitteProtocol': [
        'bitte', 'wallet', 'ai', 'competition', 'Bitte Protocol',
        'blockchain', 'NEAR', 'wallet', 'artificial intelligence',
        'technology', 'competition', 'development'
    ],
    'NEAR__SF': [
        'siliconvalley', 'silicon', 'valley', 'sanfrancisco', 'san', 'francisco',
        'usa', 'america', 'devs', 'news', 'community', 'nation', 'NEAR SF',
        'blockchain', 'NEAR', 'San Francisco', 'USA', 'developers',
        'community engagement', 'updates', 'technology'
    ],
    'DeAlmeidaDavid': [
        'validator', 'ai', 'onchain', 'fetchai', 'panda', 'pandateam',
        'David De Almeida', 'blockchain', 'NEAR', 'validator',
        'artificial intelligence', 'on-chain data', 'developer',
        'technology', 'Panda Team'
    ],
    'NEAR_China': [
        'china', 'nation', 'asia', 'community', 'NEAR China',
        'blockchain', 'NEAR', 'community engagement', 'updates',
        'localization', 'development', 'technology'
    ],
    'NEARProtocolJP': [
        'japan', 'nearjapan', 'asia', 'dev', 'news', 'community',
        'NEAR Protocol JP', 'blockchain', 'NEAR', 'Japan', 'developer',
        'community engagement', 'updates', 'localization'
    ],
    'SweatEconomy': [
        'sweat', 'economy', 'walktoearn', 'sweattoearn', 'dev', 'build',
        'Sweat Economy', 'blockchain', 'NEAR', 'move to earn',
        'fitness', 'cryptocurrency', 'development', 'health', 'wellness'
    ],
    'LearnNear': [
        'learn', 'dev', 'build', 'educate', 'Learn NEAR',
        'blockchain', 'NEAR', 'education', 'developer', 'learning',
        'development', 'resources', 'technology'
    ],
    'near_insider': [
        'news', 'learn', 'community', 'build', 'data', 'onchain',
        'NEAR Insider', 'blockchain', 'NEAR', 'updates', 'learning',
        'community engagement', 'on-chain data', 'development'
    ],
    'awesome_near': [
        'news', 'data', 'dapps', 'dappradar', 'catalogue', 'nearprotocol',
        'docs', 'community', 'Awesome NEAR', 'blockchain', 'NEAR',
        'applications', 'directory', 'documentation', 'community',
        'resources'
    ],
    'LinearProtocol': [
        'layer', 'omni', 'chain', 'liquid', 'stake', 'restake', 'abstracted',
        'chainabstraction', 'signatures', 'Linear Protocol', 'blockchain',
        'NEAR', 'layer protocol', 'chain abstraction', 'staking',
        'liquid staking', 'cryptography', 'technology'
    ],
    'Cameron_Dennis_': [
        'news', 'influencer', 'cameron', 'dev', 'thebafnetwork',
        'nearprotocol', 'community', 'Cameron Dennis', 'blockchain',
        'NEAR', 'developer', 'influencer', 'community engagement',
        'BAF Network', 'technology'
    ],
    'ParasHQ': [
        'nft', 'marketplace', 'nfts', 'paras', 'trade', 'buy', 'sell',
        'Paras HQ', 'blockchain', 'NEAR', 'NFTs', 'marketplace',
        'trading', 'digital art', 'collectibles', 'crypto art'
    ],
    'NEAR_Blockchain': [
        'news', 'community', 'trend', 'influencer', 'NEAR Blockchain',
        'blockchain', 'NEAR', 'news', 'community engagement',
        'updates', 'trends', 'technology', 'information'
    ],
    'nekotoken_xyz': [
        'meme', 'memecoins', 'neko', 'token', 'Neko Token',
        'blockchain', 'NEAR', 'cryptocurrency', 'memecoin', 'crypto asset',
        'community', 'cat-themed'
    ],
    'NearFrancais': [
        'french', 'nation', 'europe', 'francais', 'france', 'news', 'community',
        'NEAR Fran√ßais', 'blockchain', 'NEAR', 'France', 'French language',
        'community engagement', 'updates', 'localization', 'Europe'
    ],
    'billybones1_': [
        'founder', 'influencer', 'news', 'build', 'dev', 'Billy Bones',
        'blockchain', 'NEAR', 'developer', 'founder', 'influencer',
        'technology', 'development', 'community engagement'
    ],
    'FewandFarNFT': [
        'nft', 'nfts', 'community', 'art', 'Few and Far NFT',
        'blockchain', 'NEAR', 'NFTs', 'digital art', 'collectibles',
        'crypto art', 'marketplace', 'community'
    ],
    'NEARFoundation': [
        'nearfoundation', 'nearprotocol', 'news', 'community', 'dao',
        'NEAR Foundation', 'blockchain', 'NEAR', 'news', 'community engagement',
        'decentralized autonomous organization', 'development', 'updates'
    ],
}


--- File: ./src/agent/data/data_loader.py ---
import os
import logging
from langchain.text_splitter import RecursiveCharacterTextSplitter
from src.agent.data.tweet_preprocessor import load_and_process_tweets
from langchain.schema import Document
def load_documents(accounts_to_load):
    docs = []
    for account in accounts_to_load:
        folder_path = os.path.join('data', 'NEARMobileAppFollowedAccounts', account)
        if os.path.isdir(folder_path):
            logging.info(f"Loading data from {folder_path}")
            file_count = 0
            for root, dirs, files in os.walk(folder_path):
                for file in files:
                    if file.endswith('.json'):
                        file_count += 1
                        full_path = os.path.join(root, file)
                        logging.info(f"Processing file: {full_path}")
                        tweets = load_and_process_tweets(full_path)
                        docs.extend(tweets)
            if file_count == 0:
                logging.warning(f"No JSON files found in {folder_path}")
        else:
            logging.warning(f"Folder {folder_path} does not exist.")

    if not docs:
        logging.warning("No documents found for the specified accounts.")
    else:
        logging.info(f"Loaded {len(docs)} documents from account folders.")

    # Text splitting
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=2500, chunk_overlap=0
    )

    # Split documents
    split_docs = []
    for doc in docs:
        # Ensure doc is a string
        if isinstance(doc, Document):
            text = doc.page_content
        else:
            text = doc
        splits = text_splitter.split_text(text)
        for split in splits:
            split_docs.append(Document(page_content=split))

    logging.info(f"Total split documents: {len(split_docs)}")
    return split_docs


--- File: ./src/agent/data/tweet_preprocessor.py ---
import json

def load_and_process_tweets(file_path):
    with open(file_path, 'r') as file:
        tweet_data = json.load(file)
    
    processed_tweets = []
    for tweet_entry in tweet_data:
        if tweet_entry['Error'] is None and 'Tweet' in tweet_entry:
            tweet = tweet_entry['Tweet']
            # Annotate tweet text with the username to indicate the author explicitly.
            tweet_text = f"[Author: {tweet['Username']}] {tweet['Text']}"
            processed_tweets.append(tweet_text)
    
    return processed_tweets

--- File: ./src/agent/data/data_management.py ---
import logging
from src.agent.data.data_loader import load_documents
from src.agent.data.vector_store import create_vectorstore_and_retriever

def load_and_prepare_data(accounts_to_load):
    logging.info("Loading data...")
    data = load_documents(accounts_to_load)
    if not data:
        logging.warning("No data loaded. Returning None.")
        return None
    logging.info("Creating vectorstore and retriever...")
    retriever = create_vectorstore_and_retriever(data)
    return retriever


--- File: ./src/agent/search_tools/search_tools.py ---
from langchain_community.tools.tavily_search import TavilySearchResults

def get_web_search_tool():
    return TavilySearchResults()

--- File: ./src/nearm-twit-agent.py/__init__.py ---
from . import agent

--- File: ./src/nearm-twit-agent.py/streamlit_app.py ---
# src/nearm-twit-agent.py/streamlit_app.py

import sys
import os
from dotenv import load_dotenv
# Load environment variables
load_dotenv()
import logging
import time
import streamlit as st
from streamlit_extras.add_vertical_space import add_vertical_space

# Adjust the following lines to set up the correct module path
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
project_root = os.path.dirname(parent_dir)

# Insert project_root at the beginning of sys.path
sys.path.insert(0, project_root)  # Changed from append to insert

# Optional: Log the current project_root and sys.path for debugging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

logging.info(f"Project Root: {project_root}")
logging.info(f"sys.path: {sys.path}")

# Now import the necessary functions from src.agent.rag_agent
from src.agent.rag_agent import get_rag_response
from src.agent.data.account_mappings import ACCOUNT_MAPPINGS

st.set_page_config(page_title="üí¨ NEARMobile Twit Cooker", page_icon="üí¨")

# We no longer need to initialize the agent upfront since data is loaded dynamically

def get_streaming_rag_response(task: str):
    logging.info(f"Generating tweet for task: {task}")

    # Construct conversation history
    history = ""
    for msg in st.session_state['message_history']:
        role = "User" if msg["role"] == "user" else "Assistant"
        content = msg["content"]
        history += f"{role}: {content}\n"

    # Call the get_rag_response function directly
    response, steps = get_rag_response(task, history)

    words = response.split()
    for word in words:
        yield word + " "
        time.sleep(0.05)

st.title("üí¨ NEARMobile Twit Cooker")

st.markdown("""
Welcome to **NEARMobile Twit Cooker**!

I am an assistant specialized in creating **"degen style"** tweets that are both educational and informative. I can help you generate tweets based on NEAR Protocol's Twitter posts and NEARMobile partners. Let's bring your presence in the crypto community to life with fresh and relevant content!
""")

st.markdown("---")

if 'message_history' not in st.session_state:
    st.session_state['message_history'] = []

def display_chat_history():
    for msg in st.session_state['message_history']:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

display_chat_history()

if prompt := st.chat_input("Enter your task to generate a tweet:"):
    st.session_state.message_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # Display thinking animation
        thinking_placeholder = st.empty()
        with thinking_placeholder:
            for i in range(3):
                for dot in [".", "..", "..."]:
                    thinking_placeholder.markdown(f"Thinking{dot}")
                    time.sleep(0.3)
        
        # Start streaming the response
        try:
            for chunk in get_streaming_rag_response(prompt):
                thinking_placeholder.empty()  # Remove thinking animation
                full_response += chunk
                message_placeholder.markdown(full_response + "‚ñå")
            message_placeholder.markdown(full_response)
        except Exception as e:
            st.error(f"An error occurred: {e}")
            logging.error(f"Error during response generation: {e}")

    st.session_state.message_history.append({"role": "assistant", "content": full_response})

add_vertical_space(5)


